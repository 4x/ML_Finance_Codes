{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ML_in_Finance-1D-CNNs\n",
    "# Author: Matthew Dixon\n",
    "# Version: 1.0 (24.7.2019)\n",
    "# License: MIT\n",
    "# Email: matthew.dixon@iit.edu\n",
    "# Notes: tested on Mac OS X with Python 3.6 and Tensorflow 1.3.0\n",
    "# Citation: Please cite the following reference if this notebook is used for research purposes:\n",
    "# Bilokon P., Dixon M.F. and I. Halperin, Machine Learning in Finance: From Theory to Practice, Springer Graduate textbook Series, 2020. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Keras to implement a 1D convolutional neural network (CNN) for timeseries prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from keras.layers import Conv1D, Dense, MaxPooling1D, Flatten\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(threshold=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the 1D CNN\n",
    "\n",
    "We create a simple convolutional neural network: a 1D convolutional layer, followed by a dense layer.\n",
    "\n",
    "It will allow us to predict the next value in a timeseries given an input sequence of length `window_size`\n",
    "\n",
    "The `filter_length` is the length (in time-steps) of the sliding window that gets convolved with each position along each instance. The difference between 1D and 2D convolution is that a 1D filter's \"height\" is fixed to the number of input timeseries (its \"width\" being `filter_length`), and it can only slide along the window dimension.  This is useful as generally the input timeseries have no spatial/ordinal relationship, so it's not meaningful to look for patterns that are invariant with respect to subsets of the timeseries.\n",
    "`nb_filter` is the number of such filters to learn (roughly, input patterns to recognize).\n",
    "\n",
    "The model can handle multivariate timeseries (with `nb_input_series` variables) and multiple (`nb_outputs`) prediction targets. Predicting future values of a timeseries means setting these equal to one another."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_CNN(window_size, filter_length,  nb_filter=4, nb_input_series=1, nb_outputs=1):\n",
    "    \"\"\"\n",
    "    window_size (int): number of observations in each input sequence\n",
    "    filter length (int): length of the convolutional layer's filters\n",
    "    nb_filter (int): number of filters learned in the convolutional layer\n",
    "    nb_input_series (int): number of features of the input timeseries (1 for a univariate timeseries)\n",
    "    nb_outputs (int): number of features being predicted (equal to nb_input_series \n",
    "        for predicting a timeseries at a set horizon)\"\"\"\n",
    "    \n",
    "    model = Sequential((\n",
    "        # The convolutional layer learns `nb_filter` filters (aka kernels), \n",
    "        # each of size `(filter_length, nb_input_series)`.  \n",
    "        # Its output will have shape `(None, window_size - filter_length + 1, nb_filter)` ,  \n",
    "        # i.e., for each position in the input timeseries, the activation of each filter at that position.\n",
    "        Conv1D(filters=nb_filter, kernel_size=filter_length, activation='relu', input_shape=(window_size, 1)),\n",
    "        Flatten(),\n",
    "        Dense(1, activation='linear'), # For classification, a 'sigmoid' activation function would be used\n",
    "    ))\n",
    "    model.compile(loss='mse', optimizer='adam', metrics=['mae'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "CNN_model = make_CNN(window_size=50, filter_length=5, nb_filter=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input shape: (None, 50, 1)\n",
      "output shape: (None, 1)\n"
     ]
    }
   ],
   "source": [
    "print('input shape:', CNN_model.layers[0].input_shape)\n",
    "print('output shape:', CNN_model.layers[-1].output_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preparation\n",
    "  \n",
    "We define a function to format a timeseries for training the neural network. It creates corresponding arrays of input sequences `X` and output values `y`. They have the same length as each other; the remaining dimensions must match the input and output layers of the model respectively:\n",
    "\n",
    "The `X` input to the model's `fit()` method should be a 3D array of shape `(n_instances, window_size, n_ts_variables)`; each instance being a 2D array of shape `(window_size, nb_input_series)`.  For example, for `window_size = 3` and `nb_input_series = 1` (a univariate timeseries), one instance could be `[[0], [1], [2]]`\n",
    "\n",
    "For each input instance, the output is a vector of size `nb_outputs`, usually the value(s) predicted to come after the last value in that input instance, i.e., the next value in the sequence. The `y` input to ``fit()`` should be an array of shape ``(n_instances, nb_outputs)``. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_timeseries_instances(timeseries, window_size):\n",
    "    # Convert 1D vectors to 2D column vectors\n",
    "    timeseries = np.atleast_2d(timeseries)\n",
    "    if timeseries.shape[0] == 1:\n",
    "        timeseries = timeseries.T \n",
    "\n",
    "    if not 0 < window_size < timeseries.shape[0]:\n",
    "        raise ValueError('Please set 0 < window size < timeseries length')\n",
    "    \n",
    "    # `X `is the tensor containing the inputs for the model\n",
    "    # each row of `X` is a sequence of `window_size` observations from the timeseries\n",
    "    X = [timeseries[start:start + window_size] for start in range(0, timeseries.shape[0] - window_size)]\n",
    "    \n",
    "    # for training the model, the array's dimensions must match the input layer of the CNN\n",
    "    # that is, a 3D array of shape (timeseries.shape[0] - window_size, window_size, nof_ts_variables)\n",
    "    X = np.atleast_3d(np.array(X))\n",
    "    \n",
    "    # For each row of `X`, the corresponding row of `y` is the \n",
    "    # desired output -- in this case, the subsequent value in the timeseries \n",
    "    y = timeseries[window_size:]\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X:\n",
      "[[[ 1]\n",
      "  [ 1]\n",
      "  [ 2]\n",
      "  [ 3]\n",
      "  [ 5]]\n",
      "\n",
      " [[ 1]\n",
      "  [ 2]\n",
      "  [ 3]\n",
      "  [ 5]\n",
      "  [ 8]]\n",
      "\n",
      " [[ 2]\n",
      "  [ 3]\n",
      "  [ 5]\n",
      "  [ 8]\n",
      "  [13]]]\n",
      "y:\n",
      "[[ 8]\n",
      " [13]\n",
      " [21]]\n"
     ]
    }
   ],
   "source": [
    "X_fib, y_fib = make_timeseries_instances([1,1,2,3,5,8,13,21], 5)\n",
    "print('X:', X_fib, 'y:', y_fib, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a toy timeseries and split it for training and testing the CNN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeseries = np.arange(1000) # the timeseries f(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X, y = make_timeseries_instances(timeseries, window_size=50)\n",
    "\n",
    "test_ratio = 0.01 # In real life you'd usually want to use 0.2 - 0.5\n",
    "test_size = int(test_ratio * len(timeseries)) \n",
    "\n",
    "# the \"most recent\" values are used for testing the model to avoid look-ahead bias\n",
    "X_train, X_test, y_train, y_test = X[:-test_size], X[-test_size:], y[:-test_size], y[-test_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(940, 50, 1), (10, 50, 1), (940, 1), (10, 1)]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[__.shape for __ in [X_train, X_test, y_train, y_test]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[940],\n",
       "       [941],\n",
       "       [942],\n",
       "       ...,\n",
       "       [987],\n",
       "       [988],\n",
       "       [989]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([990])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that `validation_data` is not used to train the model, but allows you to monitor its out-of-sample performance during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 940 samples, validate on 10 samples\n",
      "Epoch 1/25\n",
      "940/940 [==============================] - 5s 5ms/step - loss: 343281.4171 - mae: 519.2769 - val_loss: 988153.0875 - val_mae: 994.0548\n",
      "Epoch 2/25\n",
      "940/940 [==============================] - 3s 3ms/step - loss: 342824.9544 - mae: 518.8339 - val_loss: 987283.2500 - val_mae: 993.6171\n",
      "Epoch 3/25\n",
      "940/940 [==============================] - 3s 3ms/step - loss: 342368.0035 - mae: 518.4000 - val_loss: 986404.0750 - val_mae: 993.1746\n",
      "Epoch 4/25\n",
      "940/940 [==============================] - 3s 3ms/step - loss: 341912.2947 - mae: 517.9519 - val_loss: 985534.8750 - val_mae: 992.7369\n",
      "Epoch 5/25\n",
      "940/940 [==============================] - 3s 3ms/step - loss: 341457.3739 - mae: 517.5190 - val_loss: 984660.2500 - val_mae: 992.2963\n",
      "Epoch 6/25\n",
      "940/940 [==============================] - 3s 3ms/step - loss: 341002.9669 - mae: 517.0750 - val_loss: 983791.4625 - val_mae: 991.8585\n",
      "Epoch 7/25\n",
      "940/940 [==============================] - 3s 3ms/step - loss: 340549.3203 - mae: 516.6360 - val_loss: 982919.5375 - val_mae: 991.4188\n",
      "Epoch 8/25\n",
      "940/940 [==============================] - 3s 3ms/step - loss: 340095.0849 - mae: 516.1984 - val_loss: 982049.5625 - val_mae: 990.9800\n",
      "Epoch 9/25\n",
      "940/940 [==============================] - 3s 3ms/step - loss: 339640.2930 - mae: 515.7583 - val_loss: 981172.1375 - val_mae: 990.5372\n",
      "Epoch 10/25\n",
      "940/940 [==============================] - 3s 3ms/step - loss: 339186.4452 - mae: 515.3199 - val_loss: 980301.6250 - val_mae: 990.0977\n",
      "Epoch 11/25\n",
      "940/940 [==============================] - 3s 3ms/step - loss: 338733.3991 - mae: 514.8799 - val_loss: 979431.5000 - val_mae: 989.6581\n",
      "Epoch 12/25\n",
      "940/940 [==============================] - 3s 3ms/step - loss: 338280.5966 - mae: 514.4403 - val_loss: 978558.2500 - val_mae: 989.2169\n",
      "Epoch 13/25\n",
      "940/940 [==============================] - 3s 4ms/step - loss: 337827.4105 - mae: 514.0007 - val_loss: 977690.8250 - val_mae: 988.7783\n",
      "Epoch 14/25\n",
      "940/940 [==============================] - 3s 3ms/step - loss: 337376.0337 - mae: 513.5560 - val_loss: 976823.8750 - val_mae: 988.3398\n",
      "Epoch 15/25\n",
      "940/940 [==============================] - 3s 3ms/step - loss: 336925.9795 - mae: 513.1215 - val_loss: 975957.0000 - val_mae: 987.9012\n",
      "Epoch 16/25\n",
      "940/940 [==============================] - 3s 3ms/step - loss: 336476.0028 - mae: 512.6803 - val_loss: 975087.9500 - val_mae: 987.4612\n",
      "Epoch 17/25\n",
      "940/940 [==============================] - 3s 3ms/step - loss: 336026.5252 - mae: 512.2420 - val_loss: 974223.8750 - val_mae: 987.0236\n",
      "Epoch 18/25\n",
      "940/940 [==============================] - 3s 3ms/step - loss: 335577.4605 - mae: 511.8026 - val_loss: 973356.8125 - val_mae: 986.5843\n",
      "Epoch 19/25\n",
      "940/940 [==============================] - 3s 3ms/step - loss: 335128.0635 - mae: 511.3655 - val_loss: 972491.6875 - val_mae: 986.1457\n",
      "Epoch 20/25\n",
      "940/940 [==============================] - 3s 3ms/step - loss: 334679.2174 - mae: 510.9255 - val_loss: 971624.9125 - val_mae: 985.7062\n",
      "Epoch 21/25\n",
      "940/940 [==============================] - 3s 3ms/step - loss: 334231.7936 - mae: 510.4851 - val_loss: 970762.3750 - val_mae: 985.2686\n",
      "Epoch 22/25\n",
      "940/940 [==============================] - 3s 3ms/step - loss: 333784.2876 - mae: 510.0515 - val_loss: 969899.2625 - val_mae: 984.8304\n",
      "Epoch 23/25\n",
      "940/940 [==============================] - 3s 3ms/step - loss: 333336.7005 - mae: 509.6080 - val_loss: 969033.1500 - val_mae: 984.3906\n",
      "Epoch 24/25\n",
      "940/940 [==============================] - 3s 3ms/step - loss: 332888.8096 - mae: 509.1748 - val_loss: 968167.4375 - val_mae: 983.9508\n",
      "Epoch 25/25\n",
      "940/940 [==============================] - 3s 3ms/step - loss: 332440.8676 - mae: 508.7317 - val_loss: 967303.5625 - val_mae: 983.5117\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x64aab6668>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CNN_model.fit(X_train, y_train, epochs=25, batch_size=2, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can inspect the weights of the convolutional layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[[-0.3409522 ,  0.16252264, -0.06636527, -0.4413616 ]],\n",
       " \n",
       "        [[ 0.38766423, -0.01832604,  0.37046096, -0.3154464 ]],\n",
       " \n",
       "        [[-0.30810523,  0.04050711,  0.00164559, -0.43126032]],\n",
       " \n",
       "        [[ 0.4819189 ,  0.3402339 ,  0.02723256, -0.30651313]],\n",
       " \n",
       "        [[-0.36740988,  0.06383643,  0.11094108,  0.21941969]]],\n",
       "       dtype=float32),\n",
       " array([0., 0., 0., 0.], dtype=float32)]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CNN_model.layers[0].get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making predictions with the model\n",
    "Get the predicted values for the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = CNN_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 990.          991.45458984]\n",
      " [ 991.          992.45617676]\n",
      " [ 992.          993.45770264]\n",
      " [ 993.          994.45935059]\n",
      " [ 994.          995.46081543]\n",
      " [ 995.          996.46252441]\n",
      " [ 996.          997.46411133]\n",
      " [ 997.          998.46569824]\n",
      " [ 998.          999.46740723]\n",
      " [ 999.         1000.46905518]]\n"
     ]
    }
   ],
   "source": [
    "print(np.column_stack((y_test, y_pred)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
