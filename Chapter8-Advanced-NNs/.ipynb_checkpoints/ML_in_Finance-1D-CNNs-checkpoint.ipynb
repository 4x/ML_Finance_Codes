{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ML_in_Finance-1D-CNNs\n",
    "# Author: Matthew Dixon\n",
    "# Version: 1.0 (24.7.2019)\n",
    "# License: MIT\n",
    "# Email: matthew.dixon@iit.edu\n",
    "# Notes: tested on Mac OS X with Python 3.6 and Tensorflow 1.3.0\n",
    "# Citation: Please cite the following reference if this notebook is used for research purposes:\n",
    "# Bilokon P., Dixon M.F. and I. Halperin, Machine Learning in Finance: From Theory to Practice, Springer Graduate textbook Series, 2020. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Keras to implement a 1D convolutional neural network (CNN) for timeseries prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from keras.layers import Conv1D, Dense, MaxPooling1D, Flatten\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(threshold=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the 1D CNN\n",
    "\n",
    "We create a simple convolutional neural network: a 1D convolutional layer, followed by a dense layer.\n",
    "\n",
    "It will allow us to predict the next value in a timeseries given an input sequence of length `window_size`\n",
    "\n",
    "The `filter_length` is the length (in time-steps) of the sliding window that gets convolved with each position along each instance. The difference between 1D and 2D convolution is that a 1D filter's \"height\" is fixed to the number of input timeseries (its \"width\" being `filter_length`), and it can only slide along the window dimension.  This is useful as generally the input timeseries have no spatial/ordinal relationship, so it's not meaningful to look for patterns that are invariant with respect to subsets of the timeseries.\n",
    "`nb_filter` is the number of such filters to learn (roughly, input patterns to recognize).\n",
    "\n",
    "The model can handle multivariate timeseries (with `nb_input_series` variables) and multiple (`nb_outputs`) prediction targets. Predicting future values of a timeseries means setting these equal to one another."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_CNN(window_size, filter_length,  nb_filter=4, nb_input_series=1, nb_outputs=1):\n",
    "    \"\"\"\n",
    "    window_size (int): number of observations in each input sequence\n",
    "    filter length (int): length of the convolutional layer's filters\n",
    "    nb_filter (int): number of filters learned in the convolutional layer\n",
    "    nb_input_series (int): number of features of the input timeseries (1 for a univariate timeseries)\n",
    "    nb_outputs (int): number of features being predicted (equal to nb_input_series \n",
    "        for predicting a timeseries at a set horizon)\"\"\"\n",
    "    \n",
    "    model = Sequential((\n",
    "        # The convolutional layer learns `nb_filter` filters (aka kernels), \n",
    "        # each of size `(filter_length, nb_input_series)`.  \n",
    "        # Its output will have shape `(None, window_size - filter_length + 1, nb_filter)` ,  \n",
    "        # i.e., for each position in the input timeseries, the activation of each filter at that position.\n",
    "        Conv1D(filters=nb_filter, kernel_size=filter_length, activation='relu', input_shape=(window_size, 1)),\n",
    "        Flatten(),\n",
    "        Dense(1, activation='linear'), # For classification, a 'sigmoid' activation function would be used\n",
    "    ))\n",
    "    model.compile(loss='mse', optimizer='adam', metrics=['mae'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "CNN_model = make_CNN(window_size=50, filter_length=5, nb_filter=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input shape: (None, 50, 1)\n",
      "output shape: (None, 1)\n"
     ]
    }
   ],
   "source": [
    "print('input shape:', CNN_model.layers[0].input_shape)\n",
    "print('output shape:', CNN_model.layers[-1].output_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preparation\n",
    "  \n",
    "We define a function to format a timeseries for training the neural network. It creates corresponding arrays of input sequences `X` and output values `y`. They have the same length as each other; the remaining dimensions must match the input and output layers of the model respectively:\n",
    "\n",
    "The `X` input to the model's `fit()` method should be a 3D array of shape `(n_instances, window_size, n_ts_variables)`; each instance being a 2D array of shape `(window_size, nb_input_series)`.  For example, for `window_size = 3` and `nb_input_series = 1` (a univariate timeseries), one instance could be `[[0], [1], [2]]`\n",
    "\n",
    "For each input instance, the output is a vector of size `nb_outputs`, usually the value(s) predicted to come after the last value in that input instance, i.e., the next value in the sequence. The `y` input to ``fit()`` should be an array of shape ``(n_instances, nb_outputs)``. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_timeseries_instances(timeseries, window_size):\n",
    "    # Convert 1D vectors to 2D column vectors\n",
    "    timeseries = np.atleast_2d(timeseries)\n",
    "    if timeseries.shape[0] == 1:\n",
    "        timeseries = timeseries.T \n",
    "\n",
    "    if not 0 < window_size < timeseries.shape[0]:\n",
    "        raise ValueError('Please set 0 < window size < timeseries length')\n",
    "    \n",
    "    # `X `is the tensor containing the inputs for the model\n",
    "    # each row of `X` is a sequence of `window_size` observations from the timeseries\n",
    "    X = [timeseries[start:start + window_size] for start in range(0, timeseries.shape[0] - window_size)]\n",
    "    \n",
    "    # for training the model, the array's dimensions must match the input layer of the CNN\n",
    "    # that is, a 3D array of shape (timeseries.shape[0] - window_size, window_size, nof_ts_variables)\n",
    "    X = np.atleast_3d(np.array(X))\n",
    "    \n",
    "    # For each row of `X`, the corresponding row of `y` is the \n",
    "    # desired output -- in this case, the subsequent value in the timeseries \n",
    "    y = timeseries[window_size:]\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X:\n",
      "[[[ 1]\n",
      "  [ 1]\n",
      "  [ 2]\n",
      "  [ 3]\n",
      "  [ 5]]\n",
      "\n",
      " [[ 1]\n",
      "  [ 2]\n",
      "  [ 3]\n",
      "  [ 5]\n",
      "  [ 8]]\n",
      "\n",
      " [[ 2]\n",
      "  [ 3]\n",
      "  [ 5]\n",
      "  [ 8]\n",
      "  [13]]]\n",
      "y:\n",
      "[[ 8]\n",
      " [13]\n",
      " [21]]\n"
     ]
    }
   ],
   "source": [
    "X_fib, y_fib = make_timeseries_instances([1,1,2,3,5,8,13,21], 5)\n",
    "print('X:', X_fib, 'y:', y_fib, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a toy timeseries and split it for training and testing the CNN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeseries = np.arange(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_timeseries_instances(timeseries, window_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input instance:\n",
      " [[42]\n",
      " [43]\n",
      " [44]\n",
      " ...\n",
      " [89]\n",
      " [90]\n",
      " [91]]\n",
      "output instance:\n",
      " [92]\n"
     ]
    }
   ],
   "source": [
    "i = 42\n",
    "print('input instance:\\n', X[i])\n",
    "print('output instance:\\n', y[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_ratio = 0.01 # In real life you'd usually want to use 0.2 - 0.5\n",
    "test_size = int(test_ratio * len(timeseries)) \n",
    "\n",
    "# the \"most recent\" values are used for testing the model to avoid look-ahead bias\n",
    "X_train, X_test, y_train, y_test = X[:-test_size], X[-test_size:], y[:-test_size], y[-test_size:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the dimensions of the arrays:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[i.shape for i in [X_train, X_test, y_train, y_test]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can fit the model. Note that `validation_data` is not used to train the model, but allows you to monitor its out-of-sample performance during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 940 samples, validate on 10 samples\n",
      "Epoch 1/25\n",
      "940/940 [==============================] - 5s 5ms/step - loss: 1460.8869 - mae: 14.9330 - val_loss: 67.5627 - val_mae: 8.2193\n",
      "Epoch 2/25\n",
      "940/940 [==============================] - 3s 3ms/step - loss: 78.3034 - mae: 7.4470 - val_loss: 357.8856 - val_mae: 18.9176\n",
      "Epoch 3/25\n",
      "940/940 [==============================] - 3s 3ms/step - loss: 69.5444 - mae: 7.0703 - val_loss: 113.1893 - val_mae: 10.6388\n",
      "Epoch 4/25\n",
      "940/940 [==============================] - 3s 3ms/step - loss: 60.7630 - mae: 6.5634 - val_loss: 129.0592 - val_mae: 11.3602\n",
      "Epoch 5/25\n",
      "940/940 [==============================] - 3s 3ms/step - loss: 52.6857 - mae: 6.0758 - val_loss: 78.6415 - val_mae: 8.8678\n",
      "Epoch 6/25\n",
      "940/940 [==============================] - 3s 3ms/step - loss: 44.3790 - mae: 5.5922 - val_loss: 185.6476 - val_mae: 13.6251\n",
      "Epoch 7/25\n",
      "940/940 [==============================] - 2s 3ms/step - loss: 30.4488 - mae: 4.5126 - val_loss: 0.1862 - val_mae: 0.4309\n",
      "Epoch 8/25\n",
      "940/940 [==============================] - 3s 3ms/step - loss: 25.4753 - mae: 4.0255 - val_loss: 6.8348 - val_mae: 2.6142\n",
      "Epoch 9/25\n",
      "940/940 [==============================] - 3s 3ms/step - loss: 13.5907 - mae: 3.0328 - val_loss: 58.6602 - val_mae: 7.6589\n",
      "Epoch 10/25\n",
      "940/940 [==============================] - 3s 3ms/step - loss: 11.0616 - mae: 2.6058 - val_loss: 13.6646 - val_mae: 3.6966\n",
      "Epoch 11/25\n",
      "940/940 [==============================] - 3s 3ms/step - loss: 44.3911 - mae: 3.5372 - val_loss: 0.0013 - val_mae: 0.0354\n",
      "Epoch 12/25\n",
      "940/940 [==============================] - 3s 3ms/step - loss: 4.5102 - mae: 1.6368 - val_loss: 8.6975 - val_mae: 2.9491\n",
      "Epoch 13/25\n",
      "940/940 [==============================] - 3s 3ms/step - loss: 8.5405 - mae: 1.8087 - val_loss: 0.5302 - val_mae: 0.7282\n",
      "Epoch 14/25\n",
      "940/940 [==============================] - 2s 3ms/step - loss: 3.9007 - mae: 1.2720 - val_loss: 0.8813 - val_mae: 0.9388\n",
      "Epoch 15/25\n",
      "940/940 [==============================] - 3s 3ms/step - loss: 7.1395 - mae: 1.6330 - val_loss: 23.1556 - val_mae: 4.8120\n",
      "Epoch 16/25\n",
      "940/940 [==============================] - 3s 3ms/step - loss: 25.4985 - mae: 1.8973 - val_loss: 0.0988 - val_mae: 0.3144\n",
      "Epoch 17/25\n",
      "940/940 [==============================] - 3s 3ms/step - loss: 3.6648 - mae: 0.9935 - val_loss: 0.6168 - val_mae: 0.7854\n",
      "Epoch 18/25\n",
      "940/940 [==============================] - 3s 3ms/step - loss: 0.2752 - mae: 0.3781 - val_loss: 0.0121 - val_mae: 0.1100\n",
      "Epoch 19/25\n",
      "940/940 [==============================] - 3s 3ms/step - loss: 21.3910 - mae: 1.8514 - val_loss: 0.4479 - val_mae: 0.6693\n",
      "Epoch 20/25\n",
      "940/940 [==============================] - 3s 3ms/step - loss: 2.1850 - mae: 0.7865 - val_loss: 2.9000e-04 - val_mae: 0.0170\n",
      "Epoch 21/25\n",
      "940/940 [==============================] - 3s 3ms/step - loss: 67.4349 - mae: 2.4871 - val_loss: 658.0130 - val_mae: 25.6517\n",
      "Epoch 22/25\n",
      "940/940 [==============================] - 3s 3ms/step - loss: 46.1701 - mae: 3.1467 - val_loss: 0.3411 - val_mae: 0.5840\n",
      "Epoch 23/25\n",
      "940/940 [==============================] - 3s 3ms/step - loss: 0.2950 - mae: 0.4391 - val_loss: 1.4389 - val_mae: 1.1995\n",
      "Epoch 24/25\n",
      "940/940 [==============================] - 3s 3ms/step - loss: 0.1797 - mae: 0.3374 - val_loss: 1.2063 - val_mae: 1.0983\n",
      "Epoch 25/25\n",
      "940/940 [==============================] - 3s 3ms/step - loss: 0.3311 - mae: 0.3778 - val_loss: 0.0017 - val_mae: 0.0418\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x649aa0400>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CNN_model.fit(X_train, y_train, epochs=25, batch_size=2, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can inspect the weights of the convolutional layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 46, 4)             24        \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 184)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 185       \n",
      "=================================================================\n",
      "Total params: 209\n",
      "Trainable params: 209\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "[<tf.Variable 'conv1d_1/kernel:0' shape=(5, 1, 4) dtype=float32, numpy=\n",
      "array([[[-0.44083518,  0.3101118 ,  0.15849958,  0.0360361 ]],\n",
      "\n",
      "       [[ 0.46102944,  0.40795228, -0.01246828, -0.12470502]],\n",
      "\n",
      "       [[-0.48904577, -0.01921174,  0.27507454, -0.43751034]],\n",
      "\n",
      "       [[-0.11164144, -0.3847304 ,  0.07413552, -0.11353293]],\n",
      "\n",
      "       [[ 0.02154145, -0.413403  ,  0.37336847,  0.21169254]]],\n",
      "      dtype=float32)>, <tf.Variable 'conv1d_1/bias:0' shape=(4,) dtype=float32, numpy=array([0.       , 0.       , 1.4613285, 0.       ], dtype=float32)>]\n"
     ]
    }
   ],
   "source": [
    "CNN_model.summary()\n",
    "\n",
    "print(CNN_model.get_layer('conv1d_1').weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making predictions with the model\n",
    "Get the predicted values for the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = CNN_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[990.         990.04022217]\n",
      " [991.         991.04064941]\n",
      " [992.         992.04095459]\n",
      " [993.         993.04125977]\n",
      " [994.         994.04156494]\n",
      " [995.         995.04187012]\n",
      " [996.         996.04223633]\n",
      " [997.         997.04266357]\n",
      " [998.         998.04290771]\n",
      " [999.         999.04321289]]\n"
     ]
    }
   ],
   "source": [
    "print(np.column_stack((y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
