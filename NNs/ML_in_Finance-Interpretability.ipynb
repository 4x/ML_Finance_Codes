{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ML_in_Finance-Deep-Learning-Interpretability\n",
    "# Author: Matthew Dixon\n",
    "# Version: 1.0 (08.09.2019)\n",
    "# License: MIT\n",
    "# Email: matthew.dixon@iit.edu\n",
    "# Notes: tested on Mac OS X with Python 3.6 and Tensorflow 1.3.0\n",
    "# Citation: Please cite the following reference if this notebook is used for research purposes:\n",
    "# Bilokon P., Dixon M.F. and I. Halperin, Machine Learning in Finance: From Theory to Practice, Springer Graduate textbook Series, 2020. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import math\n",
    "from datetime import datetime\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.utils import to_categorical\n",
    "from keras.regularizers import l1,l2\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.wrappers.scikit_learn import KerasRegressor, KerasClassifier\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, GridSearchCV, cross_val_score, train_test_split\n",
    "from sklearn import model_selection\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.feature_selection import f_regression\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error, r2_score, explained_variance_score, mean_absolute_error\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.stats.diagnostic as tds\n",
    "from statsmodels.api import add_constant\n",
    "from scipy import stats\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Data Generation Process (DGP)\n",
    "\n",
    "$Y=X_1+X_2 + \\epsilon, ~X_1, X_2, \\epsilon \\sim N(0,1)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = 5000 # Number of sample \n",
    "np.random.seed(7) # set the seed for reproducebility of results\n",
    "X = np.zeros(shape=(M,2))\n",
    "X[:int(M/2),0]= np.random.randn(int(M/2))\n",
    "X[:int(M/2),1]= np.random.randn(int(M/2))\n",
    "\n",
    "X[int(M/2):,0]= -X[:int(M/2),0]\n",
    "X[int(M/2):,1]= -X[:int(M/2),1]\n",
    "\n",
    "\n",
    "eps= np.zeros(shape=(M,1))\n",
    "eps[:int(M/2)]= np.random.randn(int(M/2),1)\n",
    "eps[int(M/2):]=-eps[:int(M/2)]\n",
    "Y= 1.0*X[:,0] + 1.0*X[:,1] + eps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.37365683e-17, -5.48450174e-18])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(X,axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use OLS to fit the model to the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ols_results = sm.OLS(Y, sm.add_constant(X)).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_ols=ols_results.predict(sm.add_constant(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.673</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.673</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   5150.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 11 Sep 2019</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>10:12:00</td>     <th>  Log-Likelihood:    </th> <td> -7041.3</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  5000</td>      <th>  AIC:               </th> <td>1.409e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  4997</td>      <th>  BIC:               </th> <td>1.411e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     2</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>    0.0040</td> <td>    0.014</td> <td>    0.289</td> <td> 0.773</td> <td>   -0.023</td> <td>    0.031</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>    0.9905</td> <td>    0.014</td> <td>   70.447</td> <td> 0.000</td> <td>    0.963</td> <td>    1.018</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>    1.0038</td> <td>    0.014</td> <td>   71.306</td> <td> 0.000</td> <td>    0.976</td> <td>    1.031</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 0.693</td> <th>  Durbin-Watson:     </th> <td>   1.971</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.707</td> <th>  Jarque-Bera (JB):  </th> <td>   0.643</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.020</td> <th>  Prob(JB):          </th> <td>   0.725</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.039</td> <th>  Cond. No.          </th> <td>    1.02</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.673\n",
       "Model:                            OLS   Adj. R-squared:                  0.673\n",
       "Method:                 Least Squares   F-statistic:                     5150.\n",
       "Date:                Wed, 11 Sep 2019   Prob (F-statistic):               0.00\n",
       "Time:                        10:12:00   Log-Likelihood:                -7041.3\n",
       "No. Observations:                5000   AIC:                         1.409e+04\n",
       "Df Residuals:                    4997   BIC:                         1.411e+04\n",
       "Df Model:                           2                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const          0.0040      0.014      0.289      0.773      -0.023       0.031\n",
       "x1             0.9905      0.014     70.447      0.000       0.963       1.018\n",
       "x2             1.0038      0.014     71.306      0.000       0.976       1.031\n",
       "==============================================================================\n",
       "Omnibus:                        0.693   Durbin-Watson:                   1.971\n",
       "Prob(Omnibus):                  0.707   Jarque-Bera (JB):                0.643\n",
       "Skew:                          -0.020   Prob(JB):                        0.725\n",
       "Kurtosis:                       3.039   Cond. No.                         1.02\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ols_results.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare with a ffwd neural network with no hidden layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_NN0_model(l1_reg=0.0):    \n",
    "    model = Sequential()\n",
    "    model.add(Dense(1, input_dim=2, kernel_initializer='normal')) #, activation='None'))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mae', 'mse'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor='loss', mode='min', verbose=1, patience=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = KerasRegressor(build_fn=linear_NN0_model, epochs=40, batch_size=10, verbose=1, callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "5000/5000 [==============================] - 1s 110us/step - loss: 2.3364 - mean_absolute_error: 1.2173 - mean_squared_error: 2.3364\n",
      "Epoch 2/40\n",
      "5000/5000 [==============================] - 0s 76us/step - loss: 1.4649 - mean_absolute_error: 0.9681 - mean_squared_error: 1.4649\n",
      "Epoch 3/40\n",
      "5000/5000 [==============================] - 0s 76us/step - loss: 1.1140 - mean_absolute_error: 0.8436 - mean_squared_error: 1.1140\n",
      "Epoch 4/40\n",
      "5000/5000 [==============================] - 0s 76us/step - loss: 1.0072 - mean_absolute_error: 0.8021 - mean_squared_error: 1.0072\n",
      "Epoch 5/40\n",
      "5000/5000 [==============================] - 0s 76us/step - loss: 0.9837 - mean_absolute_error: 0.7918 - mean_squared_error: 0.9837\n",
      "Epoch 6/40\n",
      "5000/5000 [==============================] - 0s 80us/step - loss: 0.9800 - mean_absolute_error: 0.7900 - mean_squared_error: 0.9800\n",
      "Epoch 7/40\n",
      "5000/5000 [==============================] - 0s 82us/step - loss: 0.9796 - mean_absolute_error: 0.7897 - mean_squared_error: 0.9796\n",
      "Epoch 8/40\n",
      "5000/5000 [==============================] - 0s 75us/step - loss: 0.9797 - mean_absolute_error: 0.7898 - mean_squared_error: 0.9797\n",
      "Epoch 9/40\n",
      "5000/5000 [==============================] - 0s 88us/step - loss: 0.9796 - mean_absolute_error: 0.7897 - mean_squared_error: 0.9796\n",
      "Epoch 10/40\n",
      "5000/5000 [==============================] - 0s 86us/step - loss: 0.9797 - mean_absolute_error: 0.7899 - mean_squared_error: 0.9797\n",
      "Epoch 11/40\n",
      "5000/5000 [==============================] - 0s 84us/step - loss: 0.9796 - mean_absolute_error: 0.7895 - mean_squared_error: 0.9796\n",
      "Epoch 12/40\n",
      "5000/5000 [==============================] - 0s 80us/step - loss: 0.9795 - mean_absolute_error: 0.7896 - mean_squared_error: 0.9795\n",
      "Epoch 13/40\n",
      "5000/5000 [==============================] - 0s 78us/step - loss: 0.9797 - mean_absolute_error: 0.7899 - mean_squared_error: 0.9797\n",
      "Epoch 14/40\n",
      "5000/5000 [==============================] - 0s 90us/step - loss: 0.9794 - mean_absolute_error: 0.7896 - mean_squared_error: 0.9794\n",
      "Epoch 15/40\n",
      "5000/5000 [==============================] - 0s 97us/step - loss: 0.9795 - mean_absolute_error: 0.7896 - mean_squared_error: 0.9795\n",
      "Epoch 16/40\n",
      "5000/5000 [==============================] - 1s 103us/step - loss: 0.9795 - mean_absolute_error: 0.7899 - mean_squared_error: 0.9795\n",
      "Epoch 17/40\n",
      "5000/5000 [==============================] - 1s 106us/step - loss: 0.9796 - mean_absolute_error: 0.7898 - mean_squared_error: 0.9796\n",
      "Epoch 18/40\n",
      "5000/5000 [==============================] - 0s 78us/step - loss: 0.9796 - mean_absolute_error: 0.7899 - mean_squared_error: 0.9796\n",
      "Epoch 19/40\n",
      "5000/5000 [==============================] - 0s 75us/step - loss: 0.9795 - mean_absolute_error: 0.7897 - mean_squared_error: 0.9795\n",
      "Epoch 20/40\n",
      "5000/5000 [==============================] - 0s 76us/step - loss: 0.9796 - mean_absolute_error: 0.7899 - mean_squared_error: 0.9796\n",
      "Epoch 21/40\n",
      "5000/5000 [==============================] - 0s 85us/step - loss: 0.9795 - mean_absolute_error: 0.7897 - mean_squared_error: 0.9795\n",
      "Epoch 22/40\n",
      "5000/5000 [==============================] - 0s 92us/step - loss: 0.9796 - mean_absolute_error: 0.7898 - mean_squared_error: 0.9796\n",
      "Epoch 23/40\n",
      "5000/5000 [==============================] - 0s 76us/step - loss: 0.9795 - mean_absolute_error: 0.7896 - mean_squared_error: 0.9795\n",
      "Epoch 24/40\n",
      "5000/5000 [==============================] - 0s 80us/step - loss: 0.9796 - mean_absolute_error: 0.7896 - mean_squared_error: 0.9796\n",
      "Epoch 00024: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c322b6e48>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.fit(X,Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check that the weights are close to one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[0.98592055],\n",
       "        [1.0046886 ]], dtype=float32), array([0.00421808], dtype=float32)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.model.get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare with a FFW Neural Network with one hidden layer (unactivated)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10 # number of hidden units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_NN1_model(l1_reg=0.0):    \n",
    "    model = Sequential()\n",
    "    model.add(Dense(n, input_dim=2, kernel_initializer='normal')) \n",
    "    model.add(Dense(1, kernel_initializer='normal', activation='linear'))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mae', 'mse'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = KerasRegressor(build_fn=linear_NN1_model, epochs=50, batch_size=10, verbose=1, callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "5000/5000 [==============================] - 1s 144us/step - loss: 1.5925 - mean_absolute_error: 0.9781 - mean_squared_error: 1.5925\n",
      "Epoch 2/50\n",
      "5000/5000 [==============================] - 0s 92us/step - loss: 0.9818 - mean_absolute_error: 0.7901 - mean_squared_error: 0.9818\n",
      "Epoch 3/50\n",
      "5000/5000 [==============================] - 1s 105us/step - loss: 0.9818 - mean_absolute_error: 0.7912 - mean_squared_error: 0.9818\n",
      "Epoch 4/50\n",
      "5000/5000 [==============================] - 1s 112us/step - loss: 0.9822 - mean_absolute_error: 0.7914 - mean_squared_error: 0.9822\n",
      "Epoch 5/50\n",
      "5000/5000 [==============================] - 0s 95us/step - loss: 0.9818 - mean_absolute_error: 0.7919 - mean_squared_error: 0.9818\n",
      "Epoch 6/50\n",
      "5000/5000 [==============================] - 1s 114us/step - loss: 0.9822 - mean_absolute_error: 0.7906 - mean_squared_error: 0.9822\n",
      "Epoch 7/50\n",
      "5000/5000 [==============================] - 0s 92us/step - loss: 0.9814 - mean_absolute_error: 0.7904 - mean_squared_error: 0.9814\n",
      "Epoch 8/50\n",
      "5000/5000 [==============================] - 0s 97us/step - loss: 0.9820 - mean_absolute_error: 0.7908 - mean_squared_error: 0.9820\n",
      "Epoch 9/50\n",
      "5000/5000 [==============================] - 0s 89us/step - loss: 0.9819 - mean_absolute_error: 0.7906 - mean_squared_error: 0.9819\n",
      "Epoch 10/50\n",
      "5000/5000 [==============================] - 0s 90us/step - loss: 0.9818 - mean_absolute_error: 0.7911 - mean_squared_error: 0.9818\n",
      "Epoch 11/50\n",
      "5000/5000 [==============================] - 0s 89us/step - loss: 0.9809 - mean_absolute_error: 0.7902 - mean_squared_error: 0.9809\n",
      "Epoch 12/50\n",
      "5000/5000 [==============================] - 0s 90us/step - loss: 0.9819 - mean_absolute_error: 0.7906 - mean_squared_error: 0.9819\n",
      "Epoch 13/50\n",
      "5000/5000 [==============================] - 0s 93us/step - loss: 0.9810 - mean_absolute_error: 0.7901 - mean_squared_error: 0.9810\n",
      "Epoch 14/50\n",
      "5000/5000 [==============================] - 1s 103us/step - loss: 0.9826 - mean_absolute_error: 0.7913 - mean_squared_error: 0.9826\n",
      "Epoch 15/50\n",
      "5000/5000 [==============================] - 1s 114us/step - loss: 0.9810 - mean_absolute_error: 0.7900 - mean_squared_error: 0.9810\n",
      "Epoch 16/50\n",
      "5000/5000 [==============================] - 1s 102us/step - loss: 0.9823 - mean_absolute_error: 0.7906 - mean_squared_error: 0.9823\n",
      "Epoch 17/50\n",
      "5000/5000 [==============================] - 0s 88us/step - loss: 0.9815 - mean_absolute_error: 0.7904 - mean_squared_error: 0.9815\n",
      "Epoch 18/50\n",
      "5000/5000 [==============================] - 0s 86us/step - loss: 0.9817 - mean_absolute_error: 0.7907 - mean_squared_error: 0.9817\n",
      "Epoch 19/50\n",
      "5000/5000 [==============================] - 0s 87us/step - loss: 0.9813 - mean_absolute_error: 0.7898 - mean_squared_error: 0.9813\n",
      "Epoch 20/50\n",
      "5000/5000 [==============================] - 0s 87us/step - loss: 0.9818 - mean_absolute_error: 0.7908 - mean_squared_error: 0.9818\n",
      "Epoch 21/50\n",
      "5000/5000 [==============================] - 0s 87us/step - loss: 0.9807 - mean_absolute_error: 0.7908 - mean_squared_error: 0.9807\n",
      "Epoch 22/50\n",
      "5000/5000 [==============================] - 0s 86us/step - loss: 0.9831 - mean_absolute_error: 0.7911 - mean_squared_error: 0.9831\n",
      "Epoch 23/50\n",
      "5000/5000 [==============================] - 1s 102us/step - loss: 0.9808 - mean_absolute_error: 0.7899 - mean_squared_error: 0.9808\n",
      "Epoch 24/50\n",
      "5000/5000 [==============================] - 1s 112us/step - loss: 0.9812 - mean_absolute_error: 0.7908 - mean_squared_error: 0.9812\n",
      "Epoch 25/50\n",
      "5000/5000 [==============================] - 0s 86us/step - loss: 0.9808 - mean_absolute_error: 0.7896 - mean_squared_error: 0.9808\n",
      "Epoch 26/50\n",
      "5000/5000 [==============================] - 0s 86us/step - loss: 0.9819 - mean_absolute_error: 0.7915 - mean_squared_error: 0.9819\n",
      "Epoch 27/50\n",
      "5000/5000 [==============================] - 0s 100us/step - loss: 0.9814 - mean_absolute_error: 0.7906 - mean_squared_error: 0.9814\n",
      "Epoch 28/50\n",
      "5000/5000 [==============================] - 1s 107us/step - loss: 0.9821 - mean_absolute_error: 0.7908 - mean_squared_error: 0.9821\n",
      "Epoch 29/50\n",
      "5000/5000 [==============================] - 0s 86us/step - loss: 0.9826 - mean_absolute_error: 0.7910 - mean_squared_error: 0.9826\n",
      "Epoch 30/50\n",
      "5000/5000 [==============================] - 0s 88us/step - loss: 0.9821 - mean_absolute_error: 0.7912 - mean_squared_error: 0.9821\n",
      "Epoch 31/50\n",
      "5000/5000 [==============================] - 0s 86us/step - loss: 0.9821 - mean_absolute_error: 0.7908 - mean_squared_error: 0.9821\n",
      "Epoch 00031: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c32798da0>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.fit(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.28151304  0.33660048 -0.32534724 -0.3117283   0.36416572  0.31704733\n",
      "  -0.3224496   0.32124516  0.28360805  0.40207058]\n",
      " [-0.3099645   0.27803436 -0.37927535 -0.2829823   0.2626483   0.31276977\n",
      "  -0.3437224   0.31792367  0.37649897  0.31318784]] [[-0.35752591]\n",
      " [ 0.33028835]\n",
      " [-0.28204554]\n",
      " [-0.31195363]\n",
      " [ 0.2602262 ]\n",
      " [ 0.344295  ]\n",
      " [-0.3088067 ]\n",
      " [ 0.30915156]\n",
      " [ 0.29915127]\n",
      " [ 0.27908695]]\n"
     ]
    }
   ],
   "source": [
    "W1=lm.model.get_weights()[0]\n",
    "b1=lm.model.get_weights()[1]\n",
    "W2=lm.model.get_weights()[2]\n",
    "b2=lm.model.get_weights()[3]\n",
    "print(W1, W2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check that the coefficients are close to one and the intercept is close to zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_0=np.dot(np.transpose(W2), b1) + b2\n",
    "beta_1=np.dot(np.transpose(W2), W1[0])\n",
    "beta_2=np.dot(np.transpose(W2), W1[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.02593422] [1.0006967] [0.9784023]\n"
     ]
    }
   ],
   "source": [
    "print(beta_0,beta_1,beta_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare with a FFW Neural Network with one hidden layer (tanh activated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of hidden neurons\n",
    "n=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with non-linear activation\n",
    "def linear_NN1_model_act(l1_reg=0.0):    \n",
    "    model = Sequential()\n",
    "    model.add(Dense(n, input_dim=2, kernel_initializer='normal', activation='tanh'))\n",
    "    model.add(Dense(1, kernel_initializer='normal')) \n",
    "    model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mae', 'mse'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = KerasRegressor(build_fn=linear_NN1_model_act, epochs=100, batch_size=10, verbose=1, callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "5000/5000 [==============================] - 1s 149us/step - loss: 1.6640 - mean_absolute_error: 1.0059 - mean_squared_error: 1.6640\n",
      "Epoch 2/100\n",
      "5000/5000 [==============================] - 0s 92us/step - loss: 1.0040 - mean_absolute_error: 0.8007 - mean_squared_error: 1.0040\n",
      "Epoch 3/100\n",
      "5000/5000 [==============================] - 0s 92us/step - loss: 1.0032 - mean_absolute_error: 0.8005 - mean_squared_error: 1.0032\n",
      "Epoch 4/100\n",
      "5000/5000 [==============================] - 0s 95us/step - loss: 0.9997 - mean_absolute_error: 0.7989 - mean_squared_error: 0.9997\n",
      "Epoch 5/100\n",
      "5000/5000 [==============================] - 0s 100us/step - loss: 0.9967 - mean_absolute_error: 0.7976 - mean_squared_error: 0.9967\n",
      "Epoch 6/100\n",
      "5000/5000 [==============================] - 0s 93us/step - loss: 0.9960 - mean_absolute_error: 0.7972 - mean_squared_error: 0.9960\n",
      "Epoch 7/100\n",
      "5000/5000 [==============================] - 0s 96us/step - loss: 0.9949 - mean_absolute_error: 0.7970 - mean_squared_error: 0.9949\n",
      "Epoch 8/100\n",
      "5000/5000 [==============================] - 1s 104us/step - loss: 0.9944 - mean_absolute_error: 0.7967 - mean_squared_error: 0.9944\n",
      "Epoch 9/100\n",
      "5000/5000 [==============================] - 0s 91us/step - loss: 0.9925 - mean_absolute_error: 0.7954 - mean_squared_error: 0.9925\n",
      "Epoch 10/100\n",
      "5000/5000 [==============================] - 0s 91us/step - loss: 0.9922 - mean_absolute_error: 0.7958 - mean_squared_error: 0.9922\n",
      "Epoch 11/100\n",
      "5000/5000 [==============================] - 1s 104us/step - loss: 0.9915 - mean_absolute_error: 0.7954 - mean_squared_error: 0.9915\n",
      "Epoch 12/100\n",
      "5000/5000 [==============================] - 0s 93us/step - loss: 0.9920 - mean_absolute_error: 0.7957 - mean_squared_error: 0.9920\n",
      "Epoch 13/100\n",
      "5000/5000 [==============================] - 0s 98us/step - loss: 0.9908 - mean_absolute_error: 0.7955 - mean_squared_error: 0.9908\n",
      "Epoch 14/100\n",
      "5000/5000 [==============================] - 1s 145us/step - loss: 0.9894 - mean_absolute_error: 0.7948 - mean_squared_error: 0.9894\n",
      "Epoch 15/100\n",
      "5000/5000 [==============================] - 1s 108us/step - loss: 0.9898 - mean_absolute_error: 0.7950 - mean_squared_error: 0.9898\n",
      "Epoch 16/100\n",
      "5000/5000 [==============================] - 1s 127us/step - loss: 0.9892 - mean_absolute_error: 0.7943 - mean_squared_error: 0.9892\n",
      "Epoch 17/100\n",
      "5000/5000 [==============================] - 1s 118us/step - loss: 0.9894 - mean_absolute_error: 0.7946 - mean_squared_error: 0.9894\n",
      "Epoch 18/100\n",
      "5000/5000 [==============================] - 0s 89us/step - loss: 0.9894 - mean_absolute_error: 0.7949 - mean_squared_error: 0.9894\n",
      "Epoch 19/100\n",
      "5000/5000 [==============================] - 0s 87us/step - loss: 0.9885 - mean_absolute_error: 0.7941 - mean_squared_error: 0.9885\n",
      "Epoch 20/100\n",
      "5000/5000 [==============================] - 0s 88us/step - loss: 0.9885 - mean_absolute_error: 0.7942 - mean_squared_error: 0.9885\n",
      "Epoch 21/100\n",
      "5000/5000 [==============================] - 0s 91us/step - loss: 0.9892 - mean_absolute_error: 0.7945 - mean_squared_error: 0.9892\n",
      "Epoch 22/100\n",
      "5000/5000 [==============================] - 0s 90us/step - loss: 0.9880 - mean_absolute_error: 0.7949 - mean_squared_error: 0.9880\n",
      "Epoch 23/100\n",
      "5000/5000 [==============================] - 1s 100us/step - loss: 0.9870 - mean_absolute_error: 0.7928 - mean_squared_error: 0.9870\n",
      "Epoch 24/100\n",
      "5000/5000 [==============================] - 1s 107us/step - loss: 0.9867 - mean_absolute_error: 0.7935 - mean_squared_error: 0.9867\n",
      "Epoch 25/100\n",
      "5000/5000 [==============================] - 0s 92us/step - loss: 0.9870 - mean_absolute_error: 0.7943 - mean_squared_error: 0.9870\n",
      "Epoch 26/100\n",
      "5000/5000 [==============================] - 0s 88us/step - loss: 0.9887 - mean_absolute_error: 0.7941 - mean_squared_error: 0.9887\n",
      "Epoch 27/100\n",
      "5000/5000 [==============================] - 0s 91us/step - loss: 0.9870 - mean_absolute_error: 0.7938 - mean_squared_error: 0.9870\n",
      "Epoch 28/100\n",
      "5000/5000 [==============================] - 0s 87us/step - loss: 0.9880 - mean_absolute_error: 0.7942 - mean_squared_error: 0.9880\n",
      "Epoch 29/100\n",
      "5000/5000 [==============================] - 0s 88us/step - loss: 0.9876 - mean_absolute_error: 0.7935 - mean_squared_error: 0.9876\n",
      "Epoch 30/100\n",
      "5000/5000 [==============================] - 0s 92us/step - loss: 0.9856 - mean_absolute_error: 0.7929 - mean_squared_error: 0.9856\n",
      "Epoch 31/100\n",
      "5000/5000 [==============================] - 0s 98us/step - loss: 0.9874 - mean_absolute_error: 0.7929 - mean_squared_error: 0.9874\n",
      "Epoch 32/100\n",
      "5000/5000 [==============================] - 1s 129us/step - loss: 0.9865 - mean_absolute_error: 0.7936 - mean_squared_error: 0.9865\n",
      "Epoch 33/100\n",
      "5000/5000 [==============================] - 0s 100us/step - loss: 0.9869 - mean_absolute_error: 0.7929 - mean_squared_error: 0.9869\n",
      "Epoch 34/100\n",
      "5000/5000 [==============================] - 0s 93us/step - loss: 0.9866 - mean_absolute_error: 0.7928 - mean_squared_error: 0.9866\n",
      "Epoch 35/100\n",
      "5000/5000 [==============================] - 0s 92us/step - loss: 0.9858 - mean_absolute_error: 0.7929 - mean_squared_error: 0.9858\n",
      "Epoch 36/100\n",
      "5000/5000 [==============================] - 0s 85us/step - loss: 0.9866 - mean_absolute_error: 0.7936 - mean_squared_error: 0.9866\n",
      "Epoch 37/100\n",
      "5000/5000 [==============================] - 0s 95us/step - loss: 0.9857 - mean_absolute_error: 0.7935 - mean_squared_error: 0.9857\n",
      "Epoch 38/100\n",
      "5000/5000 [==============================] - 1s 107us/step - loss: 0.9854 - mean_absolute_error: 0.7932 - mean_squared_error: 0.9854\n",
      "Epoch 39/100\n",
      "5000/5000 [==============================] - 1s 106us/step - loss: 0.9874 - mean_absolute_error: 0.7938 - mean_squared_error: 0.9874\n",
      "Epoch 40/100\n",
      "5000/5000 [==============================] - 1s 120us/step - loss: 0.9857 - mean_absolute_error: 0.7925 - mean_squared_error: 0.9857\n",
      "Epoch 41/100\n",
      "5000/5000 [==============================] - 1s 127us/step - loss: 0.9854 - mean_absolute_error: 0.7936 - mean_squared_error: 0.9854\n",
      "Epoch 42/100\n",
      "5000/5000 [==============================] - 1s 116us/step - loss: 0.9875 - mean_absolute_error: 0.7933 - mean_squared_error: 0.9875\n",
      "Epoch 43/100\n",
      "5000/5000 [==============================] - 1s 107us/step - loss: 0.9864 - mean_absolute_error: 0.7934 - mean_squared_error: 0.9864\n",
      "Epoch 44/100\n",
      "5000/5000 [==============================] - 1s 115us/step - loss: 0.9871 - mean_absolute_error: 0.7946 - mean_squared_error: 0.9871\n",
      "Epoch 45/100\n",
      "5000/5000 [==============================] - 0s 100us/step - loss: 0.9864 - mean_absolute_error: 0.7933 - mean_squared_error: 0.9864\n",
      "Epoch 46/100\n",
      "5000/5000 [==============================] - 1s 107us/step - loss: 0.9860 - mean_absolute_error: 0.7929 - mean_squared_error: 0.9860\n",
      "Epoch 47/100\n",
      "5000/5000 [==============================] - 1s 114us/step - loss: 0.9861 - mean_absolute_error: 0.7931 - mean_squared_error: 0.9861\n",
      "Epoch 48/100\n",
      "5000/5000 [==============================] - 1s 109us/step - loss: 0.9844 - mean_absolute_error: 0.7921 - mean_squared_error: 0.9844\n",
      "Epoch 49/100\n",
      "5000/5000 [==============================] - 1s 149us/step - loss: 0.9852 - mean_absolute_error: 0.7926 - mean_squared_error: 0.9852\n",
      "Epoch 50/100\n",
      "5000/5000 [==============================] - 1s 140us/step - loss: 0.9859 - mean_absolute_error: 0.7931 - mean_squared_error: 0.9859\n",
      "Epoch 51/100\n",
      "5000/5000 [==============================] - 1s 110us/step - loss: 0.9867 - mean_absolute_error: 0.7937 - mean_squared_error: 0.9867\n",
      "Epoch 52/100\n",
      "5000/5000 [==============================] - 1s 119us/step - loss: 0.9856 - mean_absolute_error: 0.7929 - mean_squared_error: 0.9856\n",
      "Epoch 53/100\n",
      "5000/5000 [==============================] - 1s 106us/step - loss: 0.9851 - mean_absolute_error: 0.7929 - mean_squared_error: 0.9851\n",
      "Epoch 54/100\n",
      "5000/5000 [==============================] - 1s 106us/step - loss: 0.9859 - mean_absolute_error: 0.7933 - mean_squared_error: 0.9859\n",
      "Epoch 55/100\n",
      "5000/5000 [==============================] - 1s 105us/step - loss: 0.9860 - mean_absolute_error: 0.7931 - mean_squared_error: 0.9860\n",
      "Epoch 56/100\n",
      "5000/5000 [==============================] - 1s 100us/step - loss: 0.9858 - mean_absolute_error: 0.7927 - mean_squared_error: 0.9858\n",
      "Epoch 57/100\n",
      "5000/5000 [==============================] - 1s 103us/step - loss: 0.9841 - mean_absolute_error: 0.7924 - mean_squared_error: 0.9841\n",
      "Epoch 58/100\n",
      "5000/5000 [==============================] - 0s 96us/step - loss: 0.9865 - mean_absolute_error: 0.7933 - mean_squared_error: 0.9865\n",
      "Epoch 59/100\n",
      "5000/5000 [==============================] - 0s 93us/step - loss: 0.9853 - mean_absolute_error: 0.7925 - mean_squared_error: 0.9853\n",
      "Epoch 60/100\n",
      "5000/5000 [==============================] - 1s 102us/step - loss: 0.9851 - mean_absolute_error: 0.7928 - mean_squared_error: 0.9851\n",
      "Epoch 61/100\n",
      "5000/5000 [==============================] - 1s 106us/step - loss: 0.9836 - mean_absolute_error: 0.7919 - mean_squared_error: 0.9836\n",
      "Epoch 62/100\n",
      "5000/5000 [==============================] - 1s 111us/step - loss: 0.9853 - mean_absolute_error: 0.7925 - mean_squared_error: 0.9853\n",
      "Epoch 63/100\n",
      "5000/5000 [==============================] - 0s 93us/step - loss: 0.9874 - mean_absolute_error: 0.7939 - mean_squared_error: 0.9874\n",
      "Epoch 64/100\n",
      "5000/5000 [==============================] - 0s 94us/step - loss: 0.9852 - mean_absolute_error: 0.7928 - mean_squared_error: 0.9852\n",
      "Epoch 65/100\n",
      "5000/5000 [==============================] - 1s 111us/step - loss: 0.9842 - mean_absolute_error: 0.7923 - mean_squared_error: 0.9842\n",
      "Epoch 66/100\n",
      "5000/5000 [==============================] - 0s 95us/step - loss: 0.9846 - mean_absolute_error: 0.7924 - mean_squared_error: 0.9846\n",
      "Epoch 67/100\n",
      "5000/5000 [==============================] - 1s 118us/step - loss: 0.9847 - mean_absolute_error: 0.7931 - mean_squared_error: 0.9847\n",
      "Epoch 68/100\n",
      "5000/5000 [==============================] - 1s 107us/step - loss: 0.9864 - mean_absolute_error: 0.7936 - mean_squared_error: 0.9864\n",
      "Epoch 69/100\n",
      "5000/5000 [==============================] - 1s 123us/step - loss: 0.9849 - mean_absolute_error: 0.7926 - mean_squared_error: 0.9849\n",
      "Epoch 70/100\n",
      "5000/5000 [==============================] - 0s 89us/step - loss: 0.9859 - mean_absolute_error: 0.7925 - mean_squared_error: 0.9859\n",
      "Epoch 71/100\n",
      "5000/5000 [==============================] - 0s 98us/step - loss: 0.9852 - mean_absolute_error: 0.7925 - mean_squared_error: 0.9852 0s - loss: 0.9803 - mean_absolute_error: 0.7902 - mean_squared_error: 0.\n",
      "Epoch 00071: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c32de7630>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.fit(X,Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute the sensitivities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume that the activation function is tanh\n",
    "def sensitivities(lm, X):\n",
    "    \n",
    "    W1=lm.model.get_weights()[0]\n",
    "    b1=lm.model.get_weights()[1]\n",
    "    W2=lm.model.get_weights()[2]\n",
    "    b2=lm.model.get_weights()[3]\n",
    "    \n",
    "    \n",
    "    M = np.shape(X)[0]\n",
    "    p = np.shape(X)[1]\n",
    "\n",
    "    beta=np.array([0]*M*(p+1), dtype='float32').reshape(M,p+1)\n",
    "    \n",
    "    beta[:,0]= (np.dot(np.transpose(W2),np.tanh(b1)) + b2)[0] # intercept \\beta_0= F_{W,b}(0)\n",
    "    for i in range(M):\n",
    " \n",
    "      Z1 = np.tanh(np.dot(np.transpose(W1),np.transpose(X[i,])) + b1)\n",
    "      #Z1 = np.maximum(np.dot(np.transpose(W1),np.transpose(X[i,])) + b1,0) \n",
    "      \n",
    "      D = np.diag(1-Z1**2)\n",
    "      #D = np.diag(np.sign(Z1))  \n",
    "        \n",
    "      for j in range(p):  \n",
    "          beta[i,j+1]=np.dot(np.transpose(W2),np.dot(D,W1[j]))\n",
    "            \n",
    "    return(beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta=sensitivities(lm, X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check that the intercept is close to one and the coefficients are close to one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.0288713   0.9822788   0.98537195]\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(beta, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.8812773e-06 5.4207556e-02 5.4662943e-02]\n"
     ]
    }
   ],
   "source": [
    "print(np.std(beta, axis=0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
