{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "name": "ML_in_Finance-Interpretability.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "_kFoQyUpUAGb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ML_in_Finance-Deep-Learning-Interpretability\n",
        "# Author: Matthew Dixon\n",
        "# Version: 1.0 (08.09.2019)\n",
        "# License: MIT\n",
        "# Email: matthew.dixon@iit.edu\n",
        "# Notes: tested on Mac OS X with Python 3.6 and Tensorflow 1.3.0\n",
        "# Citation: Please cite the following reference if this notebook is used for research purposes:\n",
        "# Dixon M.F., I. Halperin and P. Bilokon, Machine Learning in Finance: From Theory to Practice, Springer Graduate textbook Series, 2020. "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UudbSI59UAGm",
        "colab_type": "text"
      },
      "source": [
        "# Overview\n",
        "The purpose of this notebook is to illustrate a neural network interpretability method which is compatible with linear regression. In linear regression, provided the independent variables are scaled, one can view the regression coefficients as a measure of importance of the variables. Equivalently, the dependent variable can be differentiated w.r.t. the inputs to give the coefficient. Similarly, the derivatives of the network w.r.t. the inputs are a non-linear generalization of interpretability in linear regression. Moreover, we should expect the neural network gradients to approximate the linear regression coefficients when the data is generated by a linear regression model. Various simple experimental tests, corresponding to Section 3 of Chpt 5, are performed to illustrate the properties of network interpretability."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zfd1onEAUAGn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "fbc1c8da-b7b9-453e-aeab-e75cecfa8ce7"
      },
      "source": [
        "import random\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import math\n",
        "from datetime import datetime\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout\n",
        "from keras.utils import to_categorical\n",
        "from keras.regularizers import l1,l2\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.wrappers.scikit_learn import KerasRegressor, KerasClassifier\n",
        "from sklearn.model_selection import KFold, StratifiedKFold, GridSearchCV, cross_val_score, train_test_split\n",
        "from sklearn import model_selection\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.feature_selection import f_regression\n",
        "from sklearn import metrics\n",
        "from sklearn import preprocessing\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import mean_squared_error, r2_score, explained_variance_score, mean_absolute_error\n",
        "import statsmodels.api as sm\n",
        "import statsmodels.stats.diagnostic as tds\n",
        "from statsmodels.api import add_constant\n",
        "from scipy import stats\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n",
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3zwrQkfYUAGy",
        "colab_type": "text"
      },
      "source": [
        "# Simple Data Generation Process (DGP)\n",
        "\n",
        "\n",
        "Let us generate data from the following linear regression model\n",
        "\n",
        "$Y=X_1+X_2 + \\epsilon, ~X_1, X_2, \\epsilon \\sim N(0,1)$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "diSrymSRUAGz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "M = 5000 # Number of samples\n",
        "np.random.seed(7) # set the seed for reproducebility of results\n",
        "X = np.zeros(shape=(M,2))\n",
        "X[:int(M/2),0]= np.random.randn(int(M/2))\n",
        "X[:int(M/2),1]= np.random.randn(int(M/2))\n",
        "\n",
        "# use antithetic sampling to reduce the bias in the mean\n",
        "X[int(M/2):,0]= -X[:int(M/2),0]\n",
        "X[int(M/2):,1]= -X[:int(M/2),1]\n",
        "\n",
        "\n",
        "eps= np.zeros(shape=(M,1))\n",
        "eps[:int(M/2)]= np.random.randn(int(M/2),1)\n",
        "eps[int(M/2):]=-eps[:int(M/2)]\n",
        "Y= 1.0*X[:,0] + 1.0*X[:,1] + eps.flatten()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xthUySDyUAG7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c7f91e60-cb7e-4339-bc12-97a81b2de720"
      },
      "source": [
        "np.mean(X,axis=0)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-2.51576537e-17, -5.48450174e-18])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kx6JfSujUAHC",
        "colab_type": "text"
      },
      "source": [
        "# Use OLS to fit the model to the data\n",
        "For a baseline, let us compare the neural network with OLS regression. You should observe that the intercept is close to zero and the other coefficients are close to one."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LJTP5gc1UAHD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ols_results = sm.OLS(Y, sm.add_constant(X)).fit()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qqS2vAz_UAHL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_ols=ols_results.predict(sm.add_constant(X))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i8fHdPH3UAHQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 473
        },
        "outputId": "c2297cf9-91f8-443e-c61d-b63f1fb6bb85"
      },
      "source": [
        "ols_results.summary()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<table class=\"simpletable\">\n",
              "<caption>OLS Regression Results</caption>\n",
              "<tr>\n",
              "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.678</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.677</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   5249.</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Date:</th>             <td>Tue, 12 May 2020</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td>  \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Time:</th>                 <td>23:59:08</td>     <th>  Log-Likelihood:    </th> <td> -7020.4</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>No. Observations:</th>      <td>  5000</td>      <th>  AIC:               </th> <td>1.405e+04</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Df Residuals:</th>          <td>  4997</td>      <th>  BIC:               </th> <td>1.407e+04</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Df Model:</th>              <td>     2</td>      <th>                     </th>     <td> </td>    \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
              "</tr>\n",
              "</table>\n",
              "<table class=\"simpletable\">\n",
              "<tr>\n",
              "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>const</th> <td>-6.939e-18</td> <td>    0.014</td> <td>-4.98e-16</td> <td> 1.000</td> <td>   -0.027</td> <td>    0.027</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x1</th>    <td>    0.9858</td> <td>    0.014</td> <td>   70.409</td> <td> 0.000</td> <td>    0.958</td> <td>    1.013</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x2</th>    <td>    1.0190</td> <td>    0.014</td> <td>   72.695</td> <td> 0.000</td> <td>    0.992</td> <td>    1.047</td>\n",
              "</tr>\n",
              "</table>\n",
              "<table class=\"simpletable\">\n",
              "<tr>\n",
              "  <th>Omnibus:</th>       <td> 0.800</td> <th>  Durbin-Watson:     </th> <td>   1.941</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Prob(Omnibus):</th> <td> 0.670</td> <th>  Jarque-Bera (JB):  </th> <td>   0.750</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Skew:</th>          <td>-0.000</td> <th>  Prob(JB):          </th> <td>   0.687</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Kurtosis:</th>      <td> 3.060</td> <th>  Cond. No.          </th> <td>    1.02</td>\n",
              "</tr>\n",
              "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
            ],
            "text/plain": [
              "<class 'statsmodels.iolib.summary.Summary'>\n",
              "\"\"\"\n",
              "                            OLS Regression Results                            \n",
              "==============================================================================\n",
              "Dep. Variable:                      y   R-squared:                       0.678\n",
              "Model:                            OLS   Adj. R-squared:                  0.677\n",
              "Method:                 Least Squares   F-statistic:                     5249.\n",
              "Date:                Tue, 12 May 2020   Prob (F-statistic):               0.00\n",
              "Time:                        23:59:08   Log-Likelihood:                -7020.4\n",
              "No. Observations:                5000   AIC:                         1.405e+04\n",
              "Df Residuals:                    4997   BIC:                         1.407e+04\n",
              "Df Model:                           2                                         \n",
              "Covariance Type:            nonrobust                                         \n",
              "==============================================================================\n",
              "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
              "------------------------------------------------------------------------------\n",
              "const      -6.939e-18      0.014  -4.98e-16      1.000      -0.027       0.027\n",
              "x1             0.9858      0.014     70.409      0.000       0.958       1.013\n",
              "x2             1.0190      0.014     72.695      0.000       0.992       1.047\n",
              "==============================================================================\n",
              "Omnibus:                        0.800   Durbin-Watson:                   1.941\n",
              "Prob(Omnibus):                  0.670   Jarque-Bera (JB):                0.750\n",
              "Skew:                          -0.000   Prob(JB):                        0.687\n",
              "Kurtosis:                       3.060   Cond. No.                         1.02\n",
              "==============================================================================\n",
              "\n",
              "Warnings:\n",
              "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
              "\"\"\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m_M_l4RFUAHV",
        "colab_type": "text"
      },
      "source": [
        "# Compare with a ffwd neural network with no hidden layers\n",
        "Recall the feedforward network with no hidden layers is a linear regression model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gK7cKS-fUAHW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def linear_NN0_model(l1_reg=0.0):    \n",
        "    model = Sequential()\n",
        "    model.add(Dense(1, input_dim=2, kernel_initializer='normal'))\n",
        "    model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mae', 'mse'])\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FVNCG9q_UAHc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "es = EarlyStopping(monitor='loss', mode='min', verbose=1, patience=10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hlK793fFUAHh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lm = KerasRegressor(build_fn=linear_NN0_model, epochs=40, batch_size=10, verbose=1, callbacks=[es])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2KDwpplKUAHm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 955
        },
        "outputId": "6f4c4451-df7d-4415-98b6-f6527f319a2e"
      },
      "source": [
        "lm.fit(X,Y)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n",
            "5000/5000 [==============================] - 1s 136us/step - loss: 2.4863 - mae: 1.2602 - mse: 2.4863\n",
            "Epoch 2/40\n",
            "5000/5000 [==============================] - 0s 85us/step - loss: 1.5447 - mae: 0.9995 - mse: 1.5447\n",
            "Epoch 3/40\n",
            "5000/5000 [==============================] - 0s 89us/step - loss: 1.1417 - mae: 0.8550 - mse: 1.1417\n",
            "Epoch 4/40\n",
            "5000/5000 [==============================] - 0s 85us/step - loss: 1.0090 - mae: 0.8026 - mse: 1.0090\n",
            "Epoch 5/40\n",
            "5000/5000 [==============================] - 0s 88us/step - loss: 0.9772 - mae: 0.7890 - mse: 0.9772\n",
            "Epoch 6/40\n",
            "5000/5000 [==============================] - 0s 87us/step - loss: 0.9719 - mae: 0.7869 - mse: 0.9719\n",
            "Epoch 7/40\n",
            "5000/5000 [==============================] - 0s 86us/step - loss: 0.9712 - mae: 0.7865 - mse: 0.9712\n",
            "Epoch 8/40\n",
            "5000/5000 [==============================] - 0s 85us/step - loss: 0.9713 - mae: 0.7865 - mse: 0.9713\n",
            "Epoch 9/40\n",
            "5000/5000 [==============================] - 0s 87us/step - loss: 0.9716 - mae: 0.7868 - mse: 0.9716\n",
            "Epoch 10/40\n",
            "5000/5000 [==============================] - 0s 91us/step - loss: 0.9714 - mae: 0.7868 - mse: 0.9714\n",
            "Epoch 11/40\n",
            "5000/5000 [==============================] - 0s 88us/step - loss: 0.9714 - mae: 0.7868 - mse: 0.9714\n",
            "Epoch 12/40\n",
            "5000/5000 [==============================] - 0s 85us/step - loss: 0.9713 - mae: 0.7867 - mse: 0.9713\n",
            "Epoch 13/40\n",
            "5000/5000 [==============================] - 0s 85us/step - loss: 0.9713 - mae: 0.7867 - mse: 0.9713\n",
            "Epoch 14/40\n",
            "5000/5000 [==============================] - 0s 88us/step - loss: 0.9714 - mae: 0.7866 - mse: 0.9714\n",
            "Epoch 15/40\n",
            "5000/5000 [==============================] - 0s 87us/step - loss: 0.9716 - mae: 0.7868 - mse: 0.9716\n",
            "Epoch 16/40\n",
            "5000/5000 [==============================] - 0s 85us/step - loss: 0.9712 - mae: 0.7867 - mse: 0.9712\n",
            "Epoch 17/40\n",
            "5000/5000 [==============================] - 0s 88us/step - loss: 0.9716 - mae: 0.7870 - mse: 0.9716\n",
            "Epoch 18/40\n",
            "5000/5000 [==============================] - 0s 85us/step - loss: 0.9714 - mae: 0.7869 - mse: 0.9714\n",
            "Epoch 19/40\n",
            "5000/5000 [==============================] - 0s 85us/step - loss: 0.9714 - mae: 0.7866 - mse: 0.9714\n",
            "Epoch 20/40\n",
            "5000/5000 [==============================] - 0s 87us/step - loss: 0.9716 - mae: 0.7868 - mse: 0.9716\n",
            "Epoch 21/40\n",
            "5000/5000 [==============================] - 0s 86us/step - loss: 0.9716 - mae: 0.7867 - mse: 0.9716\n",
            "Epoch 22/40\n",
            "5000/5000 [==============================] - 0s 84us/step - loss: 0.9714 - mae: 0.7868 - mse: 0.9714\n",
            "Epoch 23/40\n",
            "5000/5000 [==============================] - 0s 85us/step - loss: 0.9713 - mae: 0.7866 - mse: 0.9713\n",
            "Epoch 24/40\n",
            "5000/5000 [==============================] - 0s 87us/step - loss: 0.9714 - mae: 0.7867 - mse: 0.9714\n",
            "Epoch 25/40\n",
            "5000/5000 [==============================] - 0s 84us/step - loss: 0.9716 - mae: 0.7870 - mse: 0.9716\n",
            "Epoch 26/40\n",
            "5000/5000 [==============================] - 0s 88us/step - loss: 0.9714 - mae: 0.7866 - mse: 0.9714\n",
            "Epoch 00026: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7fcb8b6feda0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iokoBVzTUAHs",
        "colab_type": "text"
      },
      "source": [
        "## Check that the weights are close to one\n",
        "The weights should be close to unity. The bias term is the second entry and should be close to zero."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ErrGUmQ7UAHt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "d1ec8bb8-80e2-468d-fe8b-2751f9206be8"
      },
      "source": [
        "print(\"weights: \" + str(lm.model.layers[0].get_weights()[0]))\n",
        "print(\"bias: \" + str(lm.model.layers[0].get_weights()[1]))"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "weights: [[0.9869313]\n",
            " [1.0236046]]\n",
            "bias: [0.00017654]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XeY2UlfbUAHz",
        "colab_type": "text"
      },
      "source": [
        "# Compare with a FFW Neural Network with one hidden layer (unactivated)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EEz8Yig7UAHz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n = 10 # number of hidden units"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9DXvB6wUUAH4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def linear_NN1_model(l1_reg=0.0):    \n",
        "    model = Sequential()\n",
        "    model.add(Dense(n, input_dim=2, kernel_initializer='normal')) \n",
        "    model.add(Dense(1, kernel_initializer='normal', activation='linear'))\n",
        "    model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mae', 'mse'])\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cX3ZHz0tUAH-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lm = KerasRegressor(build_fn=linear_NN1_model, epochs=50, batch_size=10, verbose=1, callbacks=[es])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "Zq6A4WMzUAIC",
        "colab_type": "code",
        "colab": {},
        "outputId": "74a5c317-fa81-4b4e-f8ad-6c374837ca4e"
      },
      "source": [
        "lm.fit(X,Y)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "5000/5000 [==============================] - 1s 144us/step - loss: 1.5925 - mean_absolute_error: 0.9781 - mean_squared_error: 1.5925\n",
            "Epoch 2/50\n",
            "5000/5000 [==============================] - 0s 92us/step - loss: 0.9818 - mean_absolute_error: 0.7901 - mean_squared_error: 0.9818\n",
            "Epoch 3/50\n",
            "5000/5000 [==============================] - 1s 105us/step - loss: 0.9818 - mean_absolute_error: 0.7912 - mean_squared_error: 0.9818\n",
            "Epoch 4/50\n",
            "5000/5000 [==============================] - 1s 112us/step - loss: 0.9822 - mean_absolute_error: 0.7914 - mean_squared_error: 0.9822\n",
            "Epoch 5/50\n",
            "5000/5000 [==============================] - 0s 95us/step - loss: 0.9818 - mean_absolute_error: 0.7919 - mean_squared_error: 0.9818\n",
            "Epoch 6/50\n",
            "5000/5000 [==============================] - 1s 114us/step - loss: 0.9822 - mean_absolute_error: 0.7906 - mean_squared_error: 0.9822\n",
            "Epoch 7/50\n",
            "5000/5000 [==============================] - 0s 92us/step - loss: 0.9814 - mean_absolute_error: 0.7904 - mean_squared_error: 0.9814\n",
            "Epoch 8/50\n",
            "5000/5000 [==============================] - 0s 97us/step - loss: 0.9820 - mean_absolute_error: 0.7908 - mean_squared_error: 0.9820\n",
            "Epoch 9/50\n",
            "5000/5000 [==============================] - 0s 89us/step - loss: 0.9819 - mean_absolute_error: 0.7906 - mean_squared_error: 0.9819\n",
            "Epoch 10/50\n",
            "5000/5000 [==============================] - 0s 90us/step - loss: 0.9818 - mean_absolute_error: 0.7911 - mean_squared_error: 0.9818\n",
            "Epoch 11/50\n",
            "5000/5000 [==============================] - 0s 89us/step - loss: 0.9809 - mean_absolute_error: 0.7902 - mean_squared_error: 0.9809\n",
            "Epoch 12/50\n",
            "5000/5000 [==============================] - 0s 90us/step - loss: 0.9819 - mean_absolute_error: 0.7906 - mean_squared_error: 0.9819\n",
            "Epoch 13/50\n",
            "5000/5000 [==============================] - 0s 93us/step - loss: 0.9810 - mean_absolute_error: 0.7901 - mean_squared_error: 0.9810\n",
            "Epoch 14/50\n",
            "5000/5000 [==============================] - 1s 103us/step - loss: 0.9826 - mean_absolute_error: 0.7913 - mean_squared_error: 0.9826\n",
            "Epoch 15/50\n",
            "5000/5000 [==============================] - 1s 114us/step - loss: 0.9810 - mean_absolute_error: 0.7900 - mean_squared_error: 0.9810\n",
            "Epoch 16/50\n",
            "5000/5000 [==============================] - 1s 102us/step - loss: 0.9823 - mean_absolute_error: 0.7906 - mean_squared_error: 0.9823\n",
            "Epoch 17/50\n",
            "5000/5000 [==============================] - 0s 88us/step - loss: 0.9815 - mean_absolute_error: 0.7904 - mean_squared_error: 0.9815\n",
            "Epoch 18/50\n",
            "5000/5000 [==============================] - 0s 86us/step - loss: 0.9817 - mean_absolute_error: 0.7907 - mean_squared_error: 0.9817\n",
            "Epoch 19/50\n",
            "5000/5000 [==============================] - 0s 87us/step - loss: 0.9813 - mean_absolute_error: 0.7898 - mean_squared_error: 0.9813\n",
            "Epoch 20/50\n",
            "5000/5000 [==============================] - 0s 87us/step - loss: 0.9818 - mean_absolute_error: 0.7908 - mean_squared_error: 0.9818\n",
            "Epoch 21/50\n",
            "5000/5000 [==============================] - 0s 87us/step - loss: 0.9807 - mean_absolute_error: 0.7908 - mean_squared_error: 0.9807\n",
            "Epoch 22/50\n",
            "5000/5000 [==============================] - 0s 86us/step - loss: 0.9831 - mean_absolute_error: 0.7911 - mean_squared_error: 0.9831\n",
            "Epoch 23/50\n",
            "5000/5000 [==============================] - 1s 102us/step - loss: 0.9808 - mean_absolute_error: 0.7899 - mean_squared_error: 0.9808\n",
            "Epoch 24/50\n",
            "5000/5000 [==============================] - 1s 112us/step - loss: 0.9812 - mean_absolute_error: 0.7908 - mean_squared_error: 0.9812\n",
            "Epoch 25/50\n",
            "5000/5000 [==============================] - 0s 86us/step - loss: 0.9808 - mean_absolute_error: 0.7896 - mean_squared_error: 0.9808\n",
            "Epoch 26/50\n",
            "5000/5000 [==============================] - 0s 86us/step - loss: 0.9819 - mean_absolute_error: 0.7915 - mean_squared_error: 0.9819\n",
            "Epoch 27/50\n",
            "5000/5000 [==============================] - 0s 100us/step - loss: 0.9814 - mean_absolute_error: 0.7906 - mean_squared_error: 0.9814\n",
            "Epoch 28/50\n",
            "5000/5000 [==============================] - 1s 107us/step - loss: 0.9821 - mean_absolute_error: 0.7908 - mean_squared_error: 0.9821\n",
            "Epoch 29/50\n",
            "5000/5000 [==============================] - 0s 86us/step - loss: 0.9826 - mean_absolute_error: 0.7910 - mean_squared_error: 0.9826\n",
            "Epoch 30/50\n",
            "5000/5000 [==============================] - 0s 88us/step - loss: 0.9821 - mean_absolute_error: 0.7912 - mean_squared_error: 0.9821\n",
            "Epoch 31/50\n",
            "5000/5000 [==============================] - 0s 86us/step - loss: 0.9821 - mean_absolute_error: 0.7908 - mean_squared_error: 0.9821\n",
            "Epoch 00031: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x1c32798da0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kcwH9k3tUAIF",
        "colab_type": "code",
        "colab": {},
        "outputId": "82b9016e-cde4-4cfa-fb58-eeb579287e2f"
      },
      "source": [
        "W1=lm.model.get_weights()[0]\n",
        "b1=lm.model.get_weights()[1]\n",
        "W2=lm.model.get_weights()[2]\n",
        "b2=lm.model.get_weights()[3]\n",
        "print(W1, W2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[-0.28151304  0.33660048 -0.32534724 -0.3117283   0.36416572  0.31704733\n",
            "  -0.3224496   0.32124516  0.28360805  0.40207058]\n",
            " [-0.3099645   0.27803436 -0.37927535 -0.2829823   0.2626483   0.31276977\n",
            "  -0.3437224   0.31792367  0.37649897  0.31318784]] [[-0.35752591]\n",
            " [ 0.33028835]\n",
            " [-0.28204554]\n",
            " [-0.31195363]\n",
            " [ 0.2602262 ]\n",
            " [ 0.344295  ]\n",
            " [-0.3088067 ]\n",
            " [ 0.30915156]\n",
            " [ 0.29915127]\n",
            " [ 0.27908695]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pgdJ8GHBUAIJ",
        "colab_type": "text"
      },
      "source": [
        "## Check that the coefficients are close to one and the intercept is close to zero"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4QUD6mBTUAIK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "beta_0=np.dot(np.transpose(W2), b1) + b2\n",
        "beta_1=np.dot(np.transpose(W2), W1[0])\n",
        "beta_2=np.dot(np.transpose(W2), W1[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GUE_8PjFUAIO",
        "colab_type": "code",
        "colab": {},
        "outputId": "1e01c6b4-8d11-4d4f-e70f-24ae7c1bb70e"
      },
      "source": [
        "print(beta_0,beta_1,beta_2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.02593422] [1.0006967] [0.9784023]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YLXKtdM8UAIS",
        "colab_type": "text"
      },
      "source": [
        "# Compare with a FFW Neural Network with one hidden layer (tanh activated)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zwVeJX1KUAIU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# number of hidden neurons\n",
        "n=10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QTrU8L9_UAIY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# with non-linear activation\n",
        "def linear_NN1_model_act(l1_reg=0.0):    \n",
        "    model = Sequential()\n",
        "    model.add(Dense(n, input_dim=2, kernel_initializer='normal', activation='tanh'))\n",
        "    model.add(Dense(1, kernel_initializer='normal')) \n",
        "    model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mae', 'mse'])\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ga1tsGQAUAIc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lm = KerasRegressor(build_fn=linear_NN1_model_act, epochs=100, batch_size=10, verbose=1, callbacks=[es])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YZwN89X8UAIg",
        "colab_type": "code",
        "colab": {},
        "outputId": "9189b597-0a6b-4035-885d-d61ec1647f28"
      },
      "source": [
        "lm.fit(X,Y)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "5000/5000 [==============================] - 1s 149us/step - loss: 1.6640 - mean_absolute_error: 1.0059 - mean_squared_error: 1.6640\n",
            "Epoch 2/100\n",
            "5000/5000 [==============================] - 0s 92us/step - loss: 1.0040 - mean_absolute_error: 0.8007 - mean_squared_error: 1.0040\n",
            "Epoch 3/100\n",
            "5000/5000 [==============================] - 0s 92us/step - loss: 1.0032 - mean_absolute_error: 0.8005 - mean_squared_error: 1.0032\n",
            "Epoch 4/100\n",
            "5000/5000 [==============================] - 0s 95us/step - loss: 0.9997 - mean_absolute_error: 0.7989 - mean_squared_error: 0.9997\n",
            "Epoch 5/100\n",
            "5000/5000 [==============================] - 0s 100us/step - loss: 0.9967 - mean_absolute_error: 0.7976 - mean_squared_error: 0.9967\n",
            "Epoch 6/100\n",
            "5000/5000 [==============================] - 0s 93us/step - loss: 0.9960 - mean_absolute_error: 0.7972 - mean_squared_error: 0.9960\n",
            "Epoch 7/100\n",
            "5000/5000 [==============================] - 0s 96us/step - loss: 0.9949 - mean_absolute_error: 0.7970 - mean_squared_error: 0.9949\n",
            "Epoch 8/100\n",
            "5000/5000 [==============================] - 1s 104us/step - loss: 0.9944 - mean_absolute_error: 0.7967 - mean_squared_error: 0.9944\n",
            "Epoch 9/100\n",
            "5000/5000 [==============================] - 0s 91us/step - loss: 0.9925 - mean_absolute_error: 0.7954 - mean_squared_error: 0.9925\n",
            "Epoch 10/100\n",
            "5000/5000 [==============================] - 0s 91us/step - loss: 0.9922 - mean_absolute_error: 0.7958 - mean_squared_error: 0.9922\n",
            "Epoch 11/100\n",
            "5000/5000 [==============================] - 1s 104us/step - loss: 0.9915 - mean_absolute_error: 0.7954 - mean_squared_error: 0.9915\n",
            "Epoch 12/100\n",
            "5000/5000 [==============================] - 0s 93us/step - loss: 0.9920 - mean_absolute_error: 0.7957 - mean_squared_error: 0.9920\n",
            "Epoch 13/100\n",
            "5000/5000 [==============================] - 0s 98us/step - loss: 0.9908 - mean_absolute_error: 0.7955 - mean_squared_error: 0.9908\n",
            "Epoch 14/100\n",
            "5000/5000 [==============================] - 1s 145us/step - loss: 0.9894 - mean_absolute_error: 0.7948 - mean_squared_error: 0.9894\n",
            "Epoch 15/100\n",
            "5000/5000 [==============================] - 1s 108us/step - loss: 0.9898 - mean_absolute_error: 0.7950 - mean_squared_error: 0.9898\n",
            "Epoch 16/100\n",
            "5000/5000 [==============================] - 1s 127us/step - loss: 0.9892 - mean_absolute_error: 0.7943 - mean_squared_error: 0.9892\n",
            "Epoch 17/100\n",
            "5000/5000 [==============================] - 1s 118us/step - loss: 0.9894 - mean_absolute_error: 0.7946 - mean_squared_error: 0.9894\n",
            "Epoch 18/100\n",
            "5000/5000 [==============================] - 0s 89us/step - loss: 0.9894 - mean_absolute_error: 0.7949 - mean_squared_error: 0.9894\n",
            "Epoch 19/100\n",
            "5000/5000 [==============================] - 0s 87us/step - loss: 0.9885 - mean_absolute_error: 0.7941 - mean_squared_error: 0.9885\n",
            "Epoch 20/100\n",
            "5000/5000 [==============================] - 0s 88us/step - loss: 0.9885 - mean_absolute_error: 0.7942 - mean_squared_error: 0.9885\n",
            "Epoch 21/100\n",
            "5000/5000 [==============================] - 0s 91us/step - loss: 0.9892 - mean_absolute_error: 0.7945 - mean_squared_error: 0.9892\n",
            "Epoch 22/100\n",
            "5000/5000 [==============================] - 0s 90us/step - loss: 0.9880 - mean_absolute_error: 0.7949 - mean_squared_error: 0.9880\n",
            "Epoch 23/100\n",
            "5000/5000 [==============================] - 1s 100us/step - loss: 0.9870 - mean_absolute_error: 0.7928 - mean_squared_error: 0.9870\n",
            "Epoch 24/100\n",
            "5000/5000 [==============================] - 1s 107us/step - loss: 0.9867 - mean_absolute_error: 0.7935 - mean_squared_error: 0.9867\n",
            "Epoch 25/100\n",
            "5000/5000 [==============================] - 0s 92us/step - loss: 0.9870 - mean_absolute_error: 0.7943 - mean_squared_error: 0.9870\n",
            "Epoch 26/100\n",
            "5000/5000 [==============================] - 0s 88us/step - loss: 0.9887 - mean_absolute_error: 0.7941 - mean_squared_error: 0.9887\n",
            "Epoch 27/100\n",
            "5000/5000 [==============================] - 0s 91us/step - loss: 0.9870 - mean_absolute_error: 0.7938 - mean_squared_error: 0.9870\n",
            "Epoch 28/100\n",
            "5000/5000 [==============================] - 0s 87us/step - loss: 0.9880 - mean_absolute_error: 0.7942 - mean_squared_error: 0.9880\n",
            "Epoch 29/100\n",
            "5000/5000 [==============================] - 0s 88us/step - loss: 0.9876 - mean_absolute_error: 0.7935 - mean_squared_error: 0.9876\n",
            "Epoch 30/100\n",
            "5000/5000 [==============================] - 0s 92us/step - loss: 0.9856 - mean_absolute_error: 0.7929 - mean_squared_error: 0.9856\n",
            "Epoch 31/100\n",
            "5000/5000 [==============================] - 0s 98us/step - loss: 0.9874 - mean_absolute_error: 0.7929 - mean_squared_error: 0.9874\n",
            "Epoch 32/100\n",
            "5000/5000 [==============================] - 1s 129us/step - loss: 0.9865 - mean_absolute_error: 0.7936 - mean_squared_error: 0.9865\n",
            "Epoch 33/100\n",
            "5000/5000 [==============================] - 0s 100us/step - loss: 0.9869 - mean_absolute_error: 0.7929 - mean_squared_error: 0.9869\n",
            "Epoch 34/100\n",
            "5000/5000 [==============================] - 0s 93us/step - loss: 0.9866 - mean_absolute_error: 0.7928 - mean_squared_error: 0.9866\n",
            "Epoch 35/100\n",
            "5000/5000 [==============================] - 0s 92us/step - loss: 0.9858 - mean_absolute_error: 0.7929 - mean_squared_error: 0.9858\n",
            "Epoch 36/100\n",
            "5000/5000 [==============================] - 0s 85us/step - loss: 0.9866 - mean_absolute_error: 0.7936 - mean_squared_error: 0.9866\n",
            "Epoch 37/100\n",
            "5000/5000 [==============================] - 0s 95us/step - loss: 0.9857 - mean_absolute_error: 0.7935 - mean_squared_error: 0.9857\n",
            "Epoch 38/100\n",
            "5000/5000 [==============================] - 1s 107us/step - loss: 0.9854 - mean_absolute_error: 0.7932 - mean_squared_error: 0.9854\n",
            "Epoch 39/100\n",
            "5000/5000 [==============================] - 1s 106us/step - loss: 0.9874 - mean_absolute_error: 0.7938 - mean_squared_error: 0.9874\n",
            "Epoch 40/100\n",
            "5000/5000 [==============================] - 1s 120us/step - loss: 0.9857 - mean_absolute_error: 0.7925 - mean_squared_error: 0.9857\n",
            "Epoch 41/100\n",
            "5000/5000 [==============================] - 1s 127us/step - loss: 0.9854 - mean_absolute_error: 0.7936 - mean_squared_error: 0.9854\n",
            "Epoch 42/100\n",
            "5000/5000 [==============================] - 1s 116us/step - loss: 0.9875 - mean_absolute_error: 0.7933 - mean_squared_error: 0.9875\n",
            "Epoch 43/100\n",
            "5000/5000 [==============================] - 1s 107us/step - loss: 0.9864 - mean_absolute_error: 0.7934 - mean_squared_error: 0.9864\n",
            "Epoch 44/100\n",
            "5000/5000 [==============================] - 1s 115us/step - loss: 0.9871 - mean_absolute_error: 0.7946 - mean_squared_error: 0.9871\n",
            "Epoch 45/100\n",
            "5000/5000 [==============================] - 0s 100us/step - loss: 0.9864 - mean_absolute_error: 0.7933 - mean_squared_error: 0.9864\n",
            "Epoch 46/100\n",
            "5000/5000 [==============================] - 1s 107us/step - loss: 0.9860 - mean_absolute_error: 0.7929 - mean_squared_error: 0.9860\n",
            "Epoch 47/100\n",
            "5000/5000 [==============================] - 1s 114us/step - loss: 0.9861 - mean_absolute_error: 0.7931 - mean_squared_error: 0.9861\n",
            "Epoch 48/100\n",
            "5000/5000 [==============================] - 1s 109us/step - loss: 0.9844 - mean_absolute_error: 0.7921 - mean_squared_error: 0.9844\n",
            "Epoch 49/100\n",
            "5000/5000 [==============================] - 1s 149us/step - loss: 0.9852 - mean_absolute_error: 0.7926 - mean_squared_error: 0.9852\n",
            "Epoch 50/100\n",
            "5000/5000 [==============================] - 1s 140us/step - loss: 0.9859 - mean_absolute_error: 0.7931 - mean_squared_error: 0.9859\n",
            "Epoch 51/100\n",
            "5000/5000 [==============================] - 1s 110us/step - loss: 0.9867 - mean_absolute_error: 0.7937 - mean_squared_error: 0.9867\n",
            "Epoch 52/100\n",
            "5000/5000 [==============================] - 1s 119us/step - loss: 0.9856 - mean_absolute_error: 0.7929 - mean_squared_error: 0.9856\n",
            "Epoch 53/100\n",
            "5000/5000 [==============================] - 1s 106us/step - loss: 0.9851 - mean_absolute_error: 0.7929 - mean_squared_error: 0.9851\n",
            "Epoch 54/100\n",
            "5000/5000 [==============================] - 1s 106us/step - loss: 0.9859 - mean_absolute_error: 0.7933 - mean_squared_error: 0.9859\n",
            "Epoch 55/100\n",
            "5000/5000 [==============================] - 1s 105us/step - loss: 0.9860 - mean_absolute_error: 0.7931 - mean_squared_error: 0.9860\n",
            "Epoch 56/100\n",
            "5000/5000 [==============================] - 1s 100us/step - loss: 0.9858 - mean_absolute_error: 0.7927 - mean_squared_error: 0.9858\n",
            "Epoch 57/100\n",
            "5000/5000 [==============================] - 1s 103us/step - loss: 0.9841 - mean_absolute_error: 0.7924 - mean_squared_error: 0.9841\n",
            "Epoch 58/100\n",
            "5000/5000 [==============================] - 0s 96us/step - loss: 0.9865 - mean_absolute_error: 0.7933 - mean_squared_error: 0.9865\n",
            "Epoch 59/100\n",
            "5000/5000 [==============================] - 0s 93us/step - loss: 0.9853 - mean_absolute_error: 0.7925 - mean_squared_error: 0.9853\n",
            "Epoch 60/100\n",
            "5000/5000 [==============================] - 1s 102us/step - loss: 0.9851 - mean_absolute_error: 0.7928 - mean_squared_error: 0.9851\n",
            "Epoch 61/100\n",
            "5000/5000 [==============================] - 1s 106us/step - loss: 0.9836 - mean_absolute_error: 0.7919 - mean_squared_error: 0.9836\n",
            "Epoch 62/100\n",
            "5000/5000 [==============================] - 1s 111us/step - loss: 0.9853 - mean_absolute_error: 0.7925 - mean_squared_error: 0.9853\n",
            "Epoch 63/100\n",
            "5000/5000 [==============================] - 0s 93us/step - loss: 0.9874 - mean_absolute_error: 0.7939 - mean_squared_error: 0.9874\n",
            "Epoch 64/100\n",
            "5000/5000 [==============================] - 0s 94us/step - loss: 0.9852 - mean_absolute_error: 0.7928 - mean_squared_error: 0.9852\n",
            "Epoch 65/100\n",
            "5000/5000 [==============================] - 1s 111us/step - loss: 0.9842 - mean_absolute_error: 0.7923 - mean_squared_error: 0.9842\n",
            "Epoch 66/100\n",
            "5000/5000 [==============================] - 0s 95us/step - loss: 0.9846 - mean_absolute_error: 0.7924 - mean_squared_error: 0.9846\n",
            "Epoch 67/100\n",
            "5000/5000 [==============================] - 1s 118us/step - loss: 0.9847 - mean_absolute_error: 0.7931 - mean_squared_error: 0.9847\n",
            "Epoch 68/100\n",
            "5000/5000 [==============================] - 1s 107us/step - loss: 0.9864 - mean_absolute_error: 0.7936 - mean_squared_error: 0.9864\n",
            "Epoch 69/100\n",
            "5000/5000 [==============================] - 1s 123us/step - loss: 0.9849 - mean_absolute_error: 0.7926 - mean_squared_error: 0.9849\n",
            "Epoch 70/100\n",
            "5000/5000 [==============================] - 0s 89us/step - loss: 0.9859 - mean_absolute_error: 0.7925 - mean_squared_error: 0.9859\n",
            "Epoch 71/100\n",
            "5000/5000 [==============================] - 0s 98us/step - loss: 0.9852 - mean_absolute_error: 0.7925 - mean_squared_error: 0.9852 0s - loss: 0.9803 - mean_absolute_error: 0.7902 - mean_squared_error: 0.\n",
            "Epoch 00071: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x1c32de7630>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mU3sy8asUAIk",
        "colab_type": "text"
      },
      "source": [
        "## Compute the Sensitivities"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xNOwwjCfUAIk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Assume that the activation function is tanh\n",
        "def sensitivities(lm, X):\n",
        "    \n",
        "    W1=lm.model.get_weights()[0]\n",
        "    b1=lm.model.get_weights()[1]\n",
        "    W2=lm.model.get_weights()[2]\n",
        "    b2=lm.model.get_weights()[3]\n",
        "    \n",
        "    \n",
        "    M = np.shape(X)[0]\n",
        "    p = np.shape(X)[1]\n",
        "\n",
        "    beta=np.array([0]*M*(p+1), dtype='float32').reshape(M,p+1)\n",
        "    \n",
        "    beta[:,0]= (np.dot(np.transpose(W2),np.tanh(b1)) + b2)[0] # intercept \\beta_0= F_{W,b}(0)\n",
        "    for i in range(M):\n",
        " \n",
        "      Z1 = np.tanh(np.dot(np.transpose(W1),np.transpose(X[i,])) + b1)\n",
        "      #Z1 = np.maximum(np.dot(np.transpose(W1),np.transpose(X[i,])) + b1,0) (ReLU)\n",
        "      \n",
        "      D = np.diag(1-Z1**2)\n",
        "      #D = np.diag(np.sign(Z1))  (ReLU)\n",
        "        \n",
        "      for j in range(p):  \n",
        "          beta[i,j+1]=np.dot(np.transpose(W2),np.dot(D,W1[j]))\n",
        "            \n",
        "    return(beta)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ux3ey5dfUAIn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "beta=sensitivities(lm, X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jiOcNG7CUAIr",
        "colab_type": "text"
      },
      "source": [
        "## Check that the intercept is close to one and the coefficients are close to one"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kWMqCNwhUAIt",
        "colab_type": "code",
        "colab": {},
        "outputId": "6c9a3082-517e-4153-d524-defc44c592b0"
      },
      "source": [
        "print(np.mean(beta, axis=0))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[-0.0288713   0.9822788   0.98537195]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pHy9jOlEUAIw",
        "colab_type": "code",
        "colab": {},
        "outputId": "6c00e092-00d7-4d1a-fd86-b6c73b9afe5e"
      },
      "source": [
        "print(np.std(beta, axis=0))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1.8812773e-06 5.4207556e-02 5.4662943e-02]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}