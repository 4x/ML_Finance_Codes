# Chapter 5 notebooks 

# Tested with 
# Python 3.6

# Installation notes

# ML_in_Finance-Deep-Learning-Interpretability 
The purpose of this notebook is to illustrate a neural network interpretability method which is compatible with linear regression. In linear regression, provided the independent variables are scaled, one can view the regression coefficients as a measure of importance of the variables. Equivalently, the dependent variable can be differentiated w.r.t. the inputs to give the coefficient. Similarly, the derivatives of the network w.r.t. the inputs are a non-linear generalization of interpretability in linear regression. Moreover, we should expect the neural network gradients to approximate the linear regression coefficients when the data is generated by a linear regression model. Various simple experimental tests, corresponding to Section 3 of Chpt 5, are performed to illustrate the properties of network interpretability.


# ML_in_Finance-Deep-Learning-Interpretability 
The purpose of this notebook is to illustrate a neural network interpretability method which is compatible with linear regression. In linear regression, provided the independent variables are scaled, one can view the regression coefficients as a measure of importance of the variables. Equivalently, the dependent variable can be differentiated w.r.t. the inputs to give the coefficient. Similarly, the derivatives of the network w.r.t. the inputs are a non-linear generalization of interpretability in linear regression. Moreover, we should expect the neural network gradients to approximate the linear regression coefficients when the data is generated by a linear regression model. Various simple experimental tests, corresponding to Section 3 of Chpt 5, are performed to illustrate the properties of network interpretability.

# ML_in_Finance-Deep-Learning-Interaction
The purpose of this notebook is to illustrate a neural network interpretability method which is compatible with linear regression, including an interaction term. In linear regression, provided the independent variables are scaled, one can view the regression coefficients as a measure of importance of the variables and their interaction effect. Equivalently, the dependent variable can be differentiated w.r.t. the inputs to give the coefficient, with the interaction obtained from the cross-term in the Hessian. Similarly, the derivatives of the network w.r.t. the inputs are a non-linear generalization of interpretability in a linear regression model with interaction effects. Moreover, we should expect the neural network gradients to approximate the regression model coefficients when the data is generated by a linear regression model with interaction terms. Various simple experimental tests, corresponding to Section 4 of Chpt 5, are performed to illustrate the properties of network interpretability.

# ML_in_Finance-Deep-Factor-Models
The purpose of this notebook is to demonstrate the application of deep learning to fundamental factor modeling. The outputs are monthly excess returns, the inputs are fundamental factor loadings (BARRA style). The data provided has already been normalized. 

The notebook describes the data loading, training using walk-forward optimization, performance evaluation and comparison with OLS regression. The toy dataset consists of 6 fundamental factors for 218 stocks over a 100 month period starting in February 2008. See the description of the smaller dataset described in Section 6.2 of Chpt 5. See Table 5.4 for a description of the factors.
